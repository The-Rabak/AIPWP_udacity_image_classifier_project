{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "from rabak_net import RabakNetwork\n",
    "from consts.consts import model_name, optimizer_name, train_dir, valid_dir, test_dir, checkpoint_path, test_image_size as image_size\n",
    "import functions as myF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = myF.get_training_transofrmers(image_size)\n",
    "\n",
    "test_transforms = myF.get_validation_transformers(image_size)\n",
    "\n",
    "train_data = myF.get_datasets_imagefolder(train_dir, train_transforms)\n",
    "validation_data = myF.get_datasets_imagefolder(valid_dir, test_transforms)\n",
    "test_data = myF.get_datasets_imagefolder(test_dir, test_transforms)\n",
    "\n",
    "image_datasets = OrderedDict([('train', train_data), ('test', test_data), ('validate', validation_data)])\n",
    "\n",
    "trainloader = myF.get_data_loader(image_datasets['train'])\n",
    "validationloader = myF.get_data_loader(image_datasets['validate'])\n",
    "testloader = myF.get_data_loader(image_datasets['test'])\n",
    "\n",
    "dataloaders = OrderedDict([('train', trainloader), ('test', testloader), ('validate', validationloader)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to\n",
    "GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module.\n",
    "\n",
    "**Note for Workspace users:** If your network is over 1 GB when saved as a checkpoint, there might be issues with saving backups in your workspace. Typically this happens with wide dense layers after the convolutional layers. If your saved checkpoint is larger than 1 GB (you can open a terminal and check with `ls -lh`), you should reduce the size of your hidden layers and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "\n",
    "if \"resnet\" in model_name:\n",
    "    model = models.resnet101(pretrained=True)\n",
    "elif \"vgg\" in model_name:\n",
    "    model = models.vgg16(pretrained=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = OrderedDict([('epochs', 4), ('lr', 0.001), ('classifier_hidden_layers', [512])])\n",
    "model_input_sizes = OrderedDict([('input', 2048), ('output', 102)])\n",
    "hyper_params['model_input_sizes'] = model_input_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze model params\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for resnet50\n",
    "# input_size, output_size = model_input_sizes['input'], model_input_sizes['output']\n",
    "# checkpoint_path = \"rabakClassifier1.pth\"\n",
    "\n",
    "# train_start_time = time.perf_counter()\n",
    "# _1024_classifier = RabakNetwork(input_size, output_size, [1024])\n",
    "# model.fc = _1024_classifier\n",
    "\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.AdamW(model.fc.parameters(), lr = 0.001)\n",
    "\n",
    "# _1024_running_train_losses, _1024_test_losses = myF.train(model, dataloaders['train'], dataloaders['test'], criterion, optimizer, epochs=5)\n",
    "\n",
    "# print(f'classifier runtime: {time.perf_counter() - train_start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# input_size, output_size = model_input_sizes['input'], model_input_sizes['output']\n",
    "# train_start_time = time.perf_counter()\n",
    "\n",
    "# _512_classifier = RabakNetwork(input_size, output_size, hyper_params['classifier_hidden_layers'])\n",
    "# model.fc = _512_classifier\n",
    "\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.AdamW(model.fc.parameters(), hyper_params['lr'])\n",
    "# _512_running_train_losses, _512_test_losses = myF.train(model, dataloaders['train'], dataloaders['validate'], criterion, optimizer, hyper_params['epochs'])\n",
    "# print(f'classifier runtime: {time.perf_counter() - train_start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_512_classifier = RabakNetwork(hyper_params['model_input_sizes']['input'], hyper_params['model_input_sizes']['output'], hyper_params['classifier_hidden_layers'])\n",
    "model.fc = _512_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if optimizer_name == \"AdamW\":\n",
    "#     optimizer = optim.AdamW(model.fc.parameters(), hyper_params['lr'])\n",
    "# elif optimizer_name == \"Adam\":\n",
    "#     optimizer = optim.Adam(model.fc.parameters(), hyper_params['lr'])\n",
    "# elif optimizer_name == \"SGD\":\n",
    "#     optimizer = optim.SGD(model.fc.parameters(), hyper_params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4 Training Loss: 4.353 Test Loss: 3.715 Test Accuracy: 0.245\n",
      "Epoch 1 / 4 Training Loss: 3.444 Test Loss: 2.655 Test Accuracy: 0.454\n",
      "Epoch 1 / 4 Training Loss: 2.646 Test Loss: 1.879 Test Accuracy: 0.580\n",
      "Epoch 1 / 4 Training Loss: 2.095 Test Loss: 1.382 Test Accuracy: 0.691\n",
      "Epoch 2 / 4 Training Loss: 1.661 Test Loss: 1.072 Test Accuracy: 0.764\n",
      "Epoch 2 / 4 Training Loss: 1.485 Test Loss: 0.969 Test Accuracy: 0.772\n",
      "Epoch 2 / 4 Training Loss: 1.290 Test Loss: 0.760 Test Accuracy: 0.822\n",
      "Epoch 2 / 4 Training Loss: 1.182 Test Loss: 0.742 Test Accuracy: 0.797\n",
      "Epoch 3 / 4 Training Loss: 1.106 Test Loss: 0.625 Test Accuracy: 0.848\n",
      "Epoch 3 / 4 Training Loss: 1.071 Test Loss: 0.561 Test Accuracy: 0.877\n",
      "Epoch 3 / 4 Training Loss: 0.999 Test Loss: 0.510 Test Accuracy: 0.874\n",
      "Epoch 3 / 4 Training Loss: 0.959 Test Loss: 0.508 Test Accuracy: 0.869\n",
      "Epoch 4 / 4 Training Loss: 0.894 Test Loss: 0.484 Test Accuracy: 0.884\n",
      "Epoch 4 / 4 Training Loss: 0.823 Test Loss: 0.466 Test Accuracy: 0.883\n",
      "Epoch 4 / 4 Training Loss: 0.883 Test Loss: 0.381 Test Accuracy: 0.903\n",
      "Epoch 4 / 4 Training Loss: 0.800 Test Loss: 0.408 Test Accuracy: 0.898\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-211b7e405d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_512_running_train_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_512_test_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'classifier runtime: {time.perf_counter() - train_start_time}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_start_time' is not defined"
     ]
    }
   ],
   "source": [
    "train_start_time = time.perf_counter()\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.__dict__[optimizer_name](model.fc.parameters(), hyper_params['lr'])\n",
    "_512_running_train_losses, _512_test_losses = myF.train(model, dataloaders['train'], dataloaders['validate'], criterion, optimizer, hyper_params['epochs'])\n",
    "print(f'classifier runtime: {time.perf_counter() - train_start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1aa03ec3670>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAHyCAYAAAC5/zvwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAABYlAAAWJQFJUiTwAACTQUlEQVR4nOzdd3hVRf7H8fek91ASCD10kB6QjjS7KzbWXrD7s7u6a1/Rte6ufW1rAZUVXXXtDaWDUqT3HjokJBBCQvr8/jjJvQkkkJCbnJTP63nOc86cMud7b0L43rlzZoy1FhERERERqRn83A5ARERERES8lKCLiIiIiNQgStBFRERERGoQJegiIiIiIjWIEnQRERERkRpECbqIiIiISA2iBF1EREREpAZRgi4iIiIiUoMoQRcRERERqUGUoIuIiIiI1CBK0EVEREREahAl6CIiIiIiNYgSdBERERGRGkQJuoiIiIhIDRJQFZUaY64CPigs3mitfaec1yUCbco4vNdaG1fJuLYAUUBiZeoRERERETmOeOCgtbZtRS/0eYJujGkFvAocAiJOoIo04KVS9h+qRFhFokJDQxt17dq1kQ/qEhEREREp1Zo1azh8+PAJXevTBN0YY4AJQArwP+C+E6jmgLV2vC/jKiaxa9eujRYtWlRF1YuIiIiIQN++fVm8eHHiiVzr6z7odwKjgGuBDB/XLSIiIiJS5/msBd0Y0xV4FnjZWjvLGDPqBKsKNsZcCbTGSfKXA7Ostfk+ClVEREREpMbySYJujAkAPgS2AQ9Vsrq4wrqK22KMudZaO7Oc8ZTVh6VLpSITEREREalivuri8legDzDOWntiveEdE4DROEl6ONADeAvnKdgfjDG9KhmniIiIiEiNVukWdGNMf5xW8+ettb9Vpi5r7eNH7FoJ3GKMOQTcC4wHLihHPX3LiHURkFCZGEVEREREqlKlWtCLdW1ZDzzqk4hK92bh+pQqvIeIiIiIiOsq28UlAugEdAWyjDG2aAEeKzzn7cJ9L1XiPkmF6/BK1CEiIiIiUuNVtotLNvBuGccScPqlzwHWAZXp/jKocL25EnWIiNQZBQUFpKamkp6eTnZ2NtZat0MSEamzjDEEBwcTGRlJo0aN8PPz9UjlJVUqQS98IPSG0o4ZY8bjJOjvW2vfKbY/EGgP5FprNxXb3w3Yba1NPaKeNsC/CouTKhOviEhdUFBQwPbt28nMzHQ7FBGResFaS1ZWFllZWWRkZNCqVasqTdJ9OpNoObUA1gBbcUZnKfJH4AFjzHRgC5COk8ifA4QA3wP/rNZIRURqoNTUVDIzMwkICCAuLo7w8PAqb80REanPCgoKyMjIYM+ePWRmZpKamkpMTEyV3c+NBL0s04HOOK3ug3D6mx/A6SLzIfCh1Xe4IiKkp6cDEBcXR2RkpMvRiIjUfX5+fp6/tzt27CA9Pb12JujW2vE4wyIeuT8RMKXsnwmUayIiEZH6LDs7G4DwcD03LyJSnYr+7hb9Ha4q+k5URKSWKfoyUd1aRESqlzFOG3NVd+rQX3cRERERkXIoStCrmhJ0EREREZEaRAl6NdmaksGKHWluhyEiIiIiNVxNGsWlTtqemslT363hp9V76NmyAV/eOrjavh4RERERkdpHLehVLDTIn2nrkrAWlm0/wO9b97sdkoiI1BMjRozwSaPQ+PHjMcYwY8aMygdVBxhjGDFiRKXr8dXPR+oeJehVLCYimAv7tPCU35612cVoRETqjvj4eIwxpS5xcXFHnZ+bm8vLL7/MtddeS+/evQkKCsIYwzvvvFNK7Y65c+fyl7/8hZNPPpnY2FiCg4Np27YtN9xwAxs3bqzKl1frVWXyWdbPvaxl4sSJVRJHXTRjxgyffQCRE6cuLtXghmFt+XjhdgB+XrOXLfsyaBuj8YtFRCorOjqau++++6j9ERERR+3LyMjwnNu0aVPi4uLYvn37Meu/6KKLSE5OZvDgwVxxxRUEBATw22+/8e677/Lxxx/z888/M2jQIF+8lCrxwQcfkJmZ6XYYPvfYY48dte+ll14iLS2Nu+66iwYNGpQ41rt3b5/ef82aNYSFhVW6nrr685HKU4JeDTo0iWRk51imr0vGWpgwdwtPnNfd7bBERGq9Bg0aMH78+HKdGxYWxvfff0/v3r1p1qwZ48eP5/HHHz/mNffccw9XXXUVzZs3L7H/6aef5uGHH+amm25ixYoVJxp+lWvdurXbIVSJ0n7mEydOJC0tjbvvvpv4+PgqvX+XLl18Uk9d/flI5amLSzW5cVg7z/anv+/gQGaOi9GIiNQ/QUFBnHXWWTRr1qzc19x///1HJedF+0NDQ1m5ciUpKSnHreett97CGMPbb79dYv97772HMYawsLCjZibs378/ISEhHD58uMT++fPnM3bsWOLi4ggKCqJVq1bcfPPN7Nq166j7ltXNJDs7m/Hjx9OuXTtPt51HHnmE7Ozs43Zv+Oyzz+jfvz9hYWE0atSISy+9lJ07d3qOJyYmYoxh5kxncvDiXU2K17t8+XIuu+wy4uPjCQ4OJjY2loSEBO6++25yc3PLvH9FFb0HOTk5PPHEE3Tu3Jng4GDGjRsHQFpaGv/4xz8YNWoULVu2JCgoiNjYWMaMGcO8efNKrbO096h4P/3jvUdHxlZcUReT8ePHs3TpUs455xwaNGhAWFgYw4cP59dffy01pt27d3PttdfSpEkTQkND6d27N++//36J+qrC7t27ue2224iPj/e8dxdeeCGLFi066tycnBxeeeUVEhISaNiwIWFhYcTHx3Peeefxyy+/lDh39uzZnHvuubRs2ZLg4GDi4uIYOHBgqR+qMzMzeeaZZ+jduzfh4eFEREQwaNAgJk+efNS51lref/99Bg8eTGxsLCEhIbRq1YozzjiDTz75xHdvTCWpBb2aDGrfmK7Noliz+yCHc/P5z/xt3Dayg9thiYjUatnZ2UyaNIlt27YRHh5Oz549OeWUU/D396/S+xpjCAhw/gstz71Gjx4NwNSpU7nxxhs9+6dNmwbA4cOH+e233zxJX1paGosXL2bYsGGEhoZ6zp8wYQI33ngjwcHBjBkzhlatWrFhwwbeeecdvvnmG+bNm3fcVllrLRdddBHfffcdHTt25Pbbbyc3N5eJEyeyatWqY177+uuv8/XXXzNmzBiGDx/O/Pnz+eSTT1i2bBlLly4lODiYBg0a8NhjjzFx4kS2bt1aojtKUcv28uXLGTBgAMYYxowZQ9u2bTl48CAbN27k9ddf58knnyQwMPC472tFXHTRRSxcuJCzzjqL888/nyZNmgBOd5WHH36YU045hXPOOYeGDRuybds2vv76a3744Qe++eYbzjzzzHLfpzzvUXn8/vvv/P3vf2fQoEHccMMNbNu2jc8//5zRo0ezdOlSOnfu7Dk3KSmJwYMHk5iYyCmnnMLgwYPZs2cPt956K6effnrF3qgK2LJlC0OHDmXXrl2MGjWKyy67jO3bt/Ppp5/y3Xff8fnnn/OHP/zBc/64ceOYPHky3bt35+qrryY0NJRdu3YxZ84cfvzxR0499VQAfvzxR8455xyioqIYM2YMLVq0IDU1lTVr1vD666+X+J06cOAAo0aNYsmSJSQkJHDddddRUFDATz/9xOWXX86qVat48sknPec//PDDPPPMM7Rt25aLL76Y6Ohodu/ezcKFC/n000+55JJLquz9qggl6NXEGMONw9ryp/8uA2Dir4ncMKwtwQFV+5+IiNQ/8Q9853YI5Zb47DmVun7Pnj1cddVVJfa1bduWCRMmMHz48ErVfSyffvop6enpDBw48Kj+zqXp0KEDrVu3Ztq0aVhrPa2m06ZNY9SoUcyYMYOpU6d6EvQZM2aQn5/PqFGjPHWsX7+em2++mfj4eGbOnEmLFt4BCKZNm8Zpp53GXXfdxRdffHHMWCZNmsR3333HsGHD+OWXXwgKCgLgiSeeYODAgce89scff2ThwoX06NHDs+/yyy9n8uTJfPXVV1x88cWebkczZsxg69atpbbcvv/++2RlZfHll19y3nnnlTi2f/9+n/TvPtLWrVtZuXIlMTExJfZ37dqVXbt2HbV/x44d9O/fn3vuuadCCXp53qPy+O6775gwYYKnpR+cb2JuueUWXn75ZV5//XXP/gcffJDExET+8pe/8Nxzz3n233333fTv37/csVfULbfcwq5du3jyySd5+OGHPftvvfVWTjnlFK655hq2bt1KREQEaWlpfPzxx/Tt25f58+cf9cG2+DdRb7/9NgUFBcyYMYNevXqVOG/fvn0lynfffTdLlizhueee4y9/+Ytnf1ZWFueffz5PP/00Y8eO9TyH8NZbb9GiRQtWrlx51O/ZkXW7SV1cqtEfejanaZTzyTk5PZuvlx79daSIiJTPtddey9SpU9mzZw8ZGRmsWLGCm2++mcTERM466yyWLVtWJffdsmULd9xxBwEBATz//PPlvm7UqFEkJyd7+qyvXr2a3bt3M3bsWBISEpg6darn3KLtopZ3gDfeeMMzEk3x5Lyo7jFjxvDNN9+Qnp5+zDjef/99AJ588klPcg5Of/5HH330mNfeeeedJRJPwPONwIIFC455bWmKfztQpGHDhvj5+T49+dvf/nZUEg7Og8al7W/ZsiVjx45l7dq1bNu2rdz38dV7NGTIkBLJOcB1111HQEBAiXpycnKYPHky0dHRPPLIIyXO79WrF1dffXW571kRO3bsYMqUKbRu3bpEYgwwePBgLrvsMlJTU/nf//4HOA2V1lqCg4NL/fk2btz4qH2l/X4U/1mlpKQwadIk+vXrd1QMISEhPPfcc1hr+eijj0ocCwwMLPWbr9J+D9yiFvRqFBTgx7jBbXnux7UAvDtnC2P7ttQYqCIiJ+DIkTy6d+/Om2++SUREBM8//zzjx48/bmtyRSUlJXHWWWeRnJzMa6+9xuDBg8t97ahRo5g4cSJTp06lZ8+enu4to0ePJjExkRdeeIH09HQiIyOZNm0aERERJVo/f/vtNwBmzpzJwoULS40tPz+f9evX07dv3zLjWLJkCX5+fqXGPnTo0GO+hn79+h21r1WrVoDT8l1el1xyCS+//DLnn38+Y8eO5dRTT2XIkCG0b9++3HVU1LFakufOncvLL7/Mb7/9RlJSEjk5JZ8T27lzZ7kf6PTVe1RaPYGBgTRt2rREPevWrePw4cP069ePyMjIo64ZOnToMYcSPVFLliwBYNiwYaV2Rxo1ahSTJk1iyZIlXH311URFRXHuuefyzTff0Lt3by666CKGDRvGgAEDjmrJvuKKK/jf//7HgAEDuOSSSxg5ciRDhgyhZcuWJc5buHAh+fn5ZfaxL3qWYc2aNSXqfvXVV+nWrRt//OMfGT58OIMGDSI6Orqyb4lPKUGvZpf3b82r0zaQmZPP2j3pzNm4j2EdY90OS0TqkMp2G6ntbrnlFp5//nlmzZrl03qTkpIYNWoU69at4+WXX+bWW2+t0PXF+6Hfc889TJ06lZYtW9KpUydGjx7N3//+d2bOnMnJJ5/MqlWrOPvssz393MHbBeAf//jHMe9z6NChYx5PS0ujUaNGJeou0rRp02NeW1p3nqJ68vPzj3ltcf3792f27Nk89dRTfPbZZ3z44YcAdO7cmccee4zLLrus3HWVV2lj4wN88cUXjB07lpCQEE477TTat29PeHg4fn5+zJgxg5kzZx71AO+x+Oo9KqvrVEBAQIl60tLSgLJ/dsf7mZ6oovuW9dB10f4DBw549n3yySc899xzfPTRR54P2CEhIYwdO5Z//vOfnlgvvPBCvv32W55//nnee+893nrrLQD69u3LM888w2mnnQZ4/00sXLiw1A+tRYr/m3jxxRdp37497733Hs8++yzPPvssAQEBnH322Tz//PN06FAzng9UF5dqFh0WyMX9WnnKb8/e4mI0IiJ1T9HDfxkZGT6rc/fu3YwYMYLVq1fz2muvceedd1a4jubNm9O5c2dPwjdjxgxP0j506FCCgoL45ZdfPN1bivc/BzwtfGlpaVhry1yO1/c+KiqK1NRU8vLyjjq2d+/eCr+uEzVo0CC+/fZb9u/fz9y5c3n00UfZu3cvl19++VEjevhCWd9WP/roowQFBfH777/z5Zdf8vzzz/PEE08wfvz4Eg9i1lRRUVFA2T+7qvqZFv0+7tmzp9Tju3fvLnEeOF1Wxo8fz/r169m2bRuTJk1i6NChTJo0ibFjx5a4/pxzzmHatGns37/f86F21apV/OEPf2D16tUl6r7nnnuO+W9i+vTpnnr9/f256667WLZsGXv37uXzzz/nggsu4Ouvv+bMM8+s0IexqqQE3QXXDWmLX+HfiVnrk1m359j9BUVEpPyKuoK0a9fuOGeWz44dOxg+fDhr167lzTffrHDLeXGjR4/m0KFDvPHGGxw4cMCToIeFhTFw4ECmTp1aoutLcUUPcM6ePfuE7w/Qp08fCgoKSh2ub86cOZWqu7iiPr7HazUODg5m8ODBPPHEE7zyyisAfPXVVz6L43g2btzISSedRNeuXUvsLygo8On7UVW6dOlCaGgoy5cvL/X5g6p6DX369PHUX9qHvaKkOCEhodTrW7VqxRVXXMFPP/1Ex44dmTNnTqlDloaHhzNq1CheeOEFHnroIXJycvjhhx8A55sYPz+/E/430aRJEy688EL++9//MmrUKDZt2sTKlStPqC5fU4LugtaNwzijm/ertndmb3YxGhGR2mfVqlWkpqYetX/r1q3cfvvtAFx55ZWVvs+2bdsYPnw4mzZt4t133+Wmm26qVH1FreLPPPNMiXLR9sqVK/n6669p3LjxUaNX3H777QQGBnLPPfewfv36o+rOyckpV6JS9NDgI488UqKvdVpaGn/7298q/qLKUPTQX2kPWM6ePdvTRaK4otbeqhjFpSzx8fFs2LChxDjy1loef/xxT0ttTRYUFMQll1xCWlpaieEEAZYtW8YHH3xQJfdt2bIlp512GomJibz00ksljs2fP5+PPvqIhg0bcsEFFwCQnJzM/Pnzj6onIyOD9PR0AgICPA8tT5069ajx/+Ho348mTZpwxRVX8Pvvv/O3v/2t1A8KmzZtYssWp7dCdnY2U6dOxVpb4pzc3FzP35Pq/N07FvVBd8kNw9rxw0rna6Gvlu7iz2d2pklkiMtRiYjUDp9++inPPvssI0eOpG3btkRGRrJp0ya+++47srKyOPvss7nvvvuOuu7ZZ59l7VrnQf2lS5cCztjiRa2MQ4cO5YYbbvCcP3z4cBITE+nbt2+ZQwaOGzeu3DNXjhw5Ej8/P5KSkujSpUuJ0VhGjx7N+PHjSU5OZuzYsUd1yejSpQvvvfce1113Hd26dePMM8+kU6dO5Obmsm3bNmbPnk1sbKzn9ZXl6quv5uOPP+bHH3+ke/fujBkzhtzcXD7//HP69evHunXrfDKKyujRo/n000+58MILOfvsswkNDaVNmzZcddVVPP/880yZMoURI0bQrl07IiIiWLVqFT/88AMNGzas9Aehirjnnnu45ZZb6NOnDxdddBGBgYHMnTuX1atXex5qrOmeffZZpk2bxt///nfmz5/P4MGD2b17N//97385++yz+fLLLyv8M127du1Ro8gUad26NU888QRvvvkmQ4YM4c9//jNTpkyhX79+nnHQ/fz8mDBhgufB1Z07dzJw4EC6du1KQkICrVq14uDBg3z77bfs2bOHO++803PuvffeS2JiIiNGjPBMgLRo0SKmTZtGmzZtuPTSSz2x/Otf/2LDhg389a9/5cMPP2To0KE0bdqUXbt2sWbNGhYuXMjkyZNp27Ythw8f5tRTTyU+Pp4BAwbQpk0bsrKy+Pnnn1mzZg1jxow56psU1xyrz05dW4BFCQkJtqa44LU5ts3939o2939r//nTWrfDEZFaYvXq1Xb16tVuh+GqGTNm2EsvvdR27tzZRkdH24CAABsTE2NPPfVU+/7779uCgoJSrxs+fLgFylyuueaaEucf69yiZfr06RWKPSEhwQL21ltvLbE/JyfHhoeHW8C+/vrrZV6/fPlye80119jWrVvboKAg27BhQ9utWzd700032alTp5b6eo90+PBh++ijj9r4+HgbFBRk27RpYx966CG7Y8cOC9jzzjuvxPmPPfZYma91y5Ytpb53eXl59sEHH7Rt27a1AQEBFrDDhw+31lr7008/2XHjxtmuXbvaqKgoGxYWZjt16mTvuOMOm5iYWPabdwxt2rSxgN2yZUu53oPiJkyYYHv16mXDwsJs48aN7fnnn2+XL19e5usu/lqKnMh7VFps06dPt4B97LHHynydbdq0OWr/jh077NVXX21jYmJsSEiI7dWrl504caL99NNPLWBffPHFY74HR97/WEuvXr1K3PeWW26xrVu3toGBgbZx48b2vPPOswsWLChR7/79++3jjz9uR44caZs3b26DgoJsXFycHT58uP3oo49K/Jv95JNP7KWXXmo7dOhgw8PDbWRkpO3WrZt96KGHbFJS0lExZ2dn21dffdUOGjTIRkVF2aCgINuqVSs7atQo++KLL9p9+/ZZa51/Y88995w988wzbatWrWxwcLCNiYmxAwYMsG+88YbNzs4u13tU3r/Bhf/WF9kTyFmNPaKZvy4zxixKSEhIKG36WTf8sGI3//efxQA0DAvk1wdGExqkiYtE5NiKhgyrMS09Umf8/PPPnH766TzwwAOebjhSuz388MM8/fTT/Pjjj5xxxhluh1MnlPdvcN++fVm8ePFia23Z456WQX3QXXR6tzhaNXIG4d+fmctni3e4HJGIiNQHxftbF0lJSeGBBx4A8PQbltqjtJ/pihUreOWVV2jUqFGVzqwrvqc+6C7y9zNcN6Qtj3/jPITy3pwtXNG/NX5+mrhIRESqzp/+9CeWLVvG4MGDiY2NZceOHfzwww+kpqZy8803V+n08FI1+vXrR4cOHejevTvh4eFs2LCB7777joKCAt58801CQvScW22iBN1lF/drxYs/r+dgVh5b9mXwy5q9nN6t9MkUREREfOHCCy9k7969fPPNNxw4cICQkBC6devGddddV+IhWak9br75Zr788ksmT55Meno6DRo04IwzzuC+++5jxIgRbocnFaQE3WXhwQFcPqANb87cBMA7c7YoQRcRkSp18cUXc/HFF7sdhvjQY4895pmdU2o/9UGvAcYNjiegsFvLgi2pLN9xwN2ARERERMQ1StBrgLjoEM7t1dxTfnv2FhejERERERE3KUGvIW4Y1taz/f2K3ew8cPQMWiIiIiJS9ylBryG6NY9mcHtnWuT8AsuEOWpFFxEREamPlKDXIDcOa+fZ/njhdtKzcl2MRkRERETcoAS9BhneKZYOTSIAOJSdxycLt7sckYiIiIhUNyXoNYifn+H6od6+6BPmJpKXX+BiRCIiIiJS3ZSg1zAX9GlB4/AgAHYeOMz3K/e4HJGIiIiIVCcl6DVMSKA/Vw1q4ym/M3sz1loXIxIRERGR6qQEvQa6amAbggOcH83yHWksTNzvckQiIlIbjRgxAmNMpesZP348xhhmzJhR+aBE5LiqJEE3xlxljLGFyw0VvLalMeY9Y8wuY0y2MSbRGPOSMaZhVcRaEzWOCObChJae8tuzN7sYjYhIzRQfH48xptQlLi7uqPNzc3N5+eWXufbaa+nduzdBQUEYY3jnnXfKvMfcuXP5y1/+wsknn0xsbCzBwcG0bduWG264gY0bN1bly6v1fPXhoDRl/dzLWiZOnOjzGCZOnHjCdRfFJVKWAF9XaIxpBbwKHAIiKnhte+BXoAnwFbAW6A/cBZxpjBlirU3xbcQ10/VD2zJ5wTYAflmzly37MmgbE+5yVCIiNUt0dDR33333UfsjIo7+7ycjI8NzbtOmTYmLi2P79mOPlnXRRReRnJzM4MGDueKKKwgICOC3337j3Xff5eOPP+bnn39m0KBBvngpVeKDDz4gMzPT7TB87rHHHjtq30svvURaWhp33XUXDRo0KHGsd+/e1ROYiI/4NEE3zsfBCUAK8D/gvgpW8TpOcn6ntfbVYvW+ANwDPAXc4ptoa7YOTSIY1aUJ09YmYS28O2czT57fw+2wRERqlAYNGjB+/PhynRsWFsb3339P7969adasGePHj+fxxx8/5jX33HMPV111Fc2bNy+x/+mnn+bhhx/mpptuYsWKFScafpVr3bq12yFUidJ+5hMnTiQtLY27776b+Pj4ao9JxJd83cXlTmAUcC2QUZELjTHtgNOBROC1Iw4/VljfVcaYetOMfMMw75CLny3awf6MHBejERGp3YKCgjjrrLNo1qxZua+5//77j0rOi/aHhoaycuVKUlKO/8XuW2+9hTGGt99+u8T+9957D2MMYWFhZGdnlzjWv39/QkJCOHz4cIn98+fPZ+zYscTFxREUFESrVq24+eab2bVr11H3LaubSXZ2NuPHj6ddu3aebjuPPPII2dnZGGMYMWJEma/ls88+o3///oSFhdGoUSMuvfRSdu7c6TmemJiIMYaZM2cCJbujFK93+fLlXHbZZcTHxxMcHExsbCwJCQncfffd5Ob6dqK+irxnmzdv5qabbqJDhw6EhobSqFEjevTowS233OL5WY8YMYJrr70WgGuvvbbEa0xMTPRp7NnZ2Tz77LP07NmTsLAwoqKiGDZsGP/9739LPf/rr79m9OjRNGvWjODgYJo3b87w4cN5/fXXK/w6i5s8eTIjR46kYcOGhISE0LVrV5588smjfm8BZs+ezbnnnkvLli0JDg4mLi6OgQMHHvcDsXj5rAXdGNMVeBZ42Vo7yxgzqoJVFJ0/xVpbYvBva226MWYuTgI/EJha6YBrgUHtGtOteRSrdh0kK7eA/8zfyu2jOrodlohIjZGdnc2kSZPYtm0b4eHh9OzZk1NOOQV/f/8qva8xhoAA57/Q8txr9OjRAEydOpUbb7zRs3/atGkAHD58mN9++82TwKalpbF48WKGDRtGaGio5/wJEyZw4403EhwczJgxY2jVqhUbNmzgnXfe4ZtvvmHevHnHbTW31nLRRRfx3Xff0bFjR26//XZyc3OZOHEiq1atOua1r7/+Ol9//TVjxoxh+PDhzJ8/n08++YRly5axdOlSgoODadCgAY899hgTJ05k69atJbqjFLVsL1++nAEDBmCMYcyYMbRt25aDBw+yceNGXn/9dZ588kkCAwOP+76WR0Xes927d3PyySdz8OBBzj77bC666CKysrLYsmULH374IbfffjuNGzdm3LhxNGjQgK+++orzzjuvRBeaI7vXVEZOTg5nnHEGM2fOpEuXLtx2221kZmby2Wefcckll7B06VKefvppz/n//ve/ufnmm4mLi+Pcc88lJiaGpKQkli9fzoQJE7j11lsr9DqLXH/99bz33nu0bNmSCy+8kAYNGjBv3jweffRRpk6dys8//+z59/Djjz9yzjnnEBUVxZgxY2jRogWpqamsWbOG119/vdTuSXI0nyToxpgA4ENgG/DQCVbTuXC9vozjG3AS9E4cJ0E3xiwq41CXEwvNHcYYbhzWjrs/WQrA+79t5cZT2hEcULX/8YhILTc+2u0Iym98WqUu37NnD1dddVWJfW3btmXChAkMHz68UnUfy6effkp6ejoDBw4sV0LWoUMHWrduzbRp07DWelq1p02bxqhRo5gxYwZTp071JOgzZswgPz+fUaO8bV3r16/n5ptvJj4+npkzZ9KiRQvPsWnTpnHaaadx11138cUXXxwzlkmTJvHdd98xbNgwfvnlF4KCnLk3nnjiCQYOHHjMa3/88UcWLlxIjx7eLpeXX345kydP5quvvuLiiy/2dDuaMWMGW7duLbU7yvvvv09WVhZffvkl5513Xolj+/fvJyws7JhxlFdF37PPPvuM1NRUXnrpJe66664SdWVkZODn53Q8GDduHABfffUV559/vqfsa88//zwzZ87krLPO4uuvv/YkwY899hj9+/fnmWee4Q9/+AODBw8GnG9qgoKCWLZsGU2aNClR1759+zzb5X2d4HQdeu+997jgggv4z3/+U+IDY1E3sddee81Tz9tvv01BQQEzZsygV69eZcYgx+arLi5/BfoA46y1h493chmK/kcp66910f4GJ1h/rXROz2bERYUAkJyezVdLj/46TkSkPrr22muZOnUqe/bsISMjgxUrVnDzzTeTmJjIWWedxbJly6rkvlu2bOGOO+4gICCA559/vtzXjRo1iuTkZE+f9dWrV7N7927Gjh1LQkICU6d6256Ktota3gHeeOMNz0g0xRPNorrHjBnDN998Q3p6+jHjeP/99wF48sknPck5OC2/jz766DGvvfPOO0sk54DnG4EFCxYc89rSFE/2ijRs2LBEglgZJ/qelRZXeHh4qfurUlEXqBdeeMGTnAM0adLE87M6chSigICAUr99iImJOWpfeV7nyy+/TEBAAO+9995R5z/66KM0btyY//znP+Wqu7QYpHSVbkE3xvTHaTV/3lr7W+VDKvtWhevjztpjre1bagVOy3qCL4OqaoH+fowbEs+zP6wF4N3ZW/hj35YanklE6r0jvyrv3r07b775JhERETz//POMHz/+uK3JFZWUlMRZZ51FcnIyr732mqflsjxGjRrFxIkTmTp1Kj179vR0bxk9ejSJiYm88MILpKenExkZybRp04iIiKB///6e63/7zfkvdubMmSxcuLDU2PLz81m/fj19+5b63yAAS5Yswc/Pr9TYhw4deszX0K9fv6P2tWrVCnBavsvrkksu4eWXX+b8889n7NixnHrqqQwZMoT27duXu47yqOh7NmbMGB566CFuu+02fvrpJ8444wyGDBnCSSedVO3/76anp7Nx40ZatGhBly5HdwAo+nZlyZIlnn1XXHEF9957L926deOSSy5h+PDhDBkyhNjY2BLXlvd1ZmZmsmzZMmJiYnjppZdKjTM4OJg1a9aUiOF///sfAwYM4JJLLmHkyJEMGTKEli1blnq9lMFae8ILToK/DlgNBB9xbDxOMn1DOev6R+H595Zx/F+Fx/+vEvEuSkhIsLXNgcwce9KjP9g2939r29z/rZ2xLsntkETERatXr7arV692O4waa8OGDRawjRo1OuZ5jz32mAXs22+/Xa569+7da7t162YB+/LLL1c4rp07d1rAnnPOOdZaa88//3zbsmVLa621P/30kwXsN998Y/fs2WMBe/bZZ5e4vkOHDrbw/8FjLjNmzPBcM3z4cOv8V+/l7+9vY2JiSo3x8OHDFrDDhw8vsb/ovZo+ffpR12zZssUC9pprrimxv7R7F/frr7/ac845x4aGhnpi79y5s/3oo4/KvOZY2rRpYwG7ZcsWz74Tec9Wr15tL774YhsVFeU53qpVq6N+5hMmTLCAnTBhQoVjLar3WLZv324B269fv1KPF/2s4uPjS+x///337YABA6yfn58FrDHGjhgxwi5cuLDEeeV5nTt27CjX+3fka/n222/tyJEjbWBgoOd437597ZQpUyryNtVY5f0bnJCQYIFF9gRy1sp+hxSB0ye8K5BVbHIiizPyCsDbhfteOk5d6wrXnco4XvR0ZFl91Ous6NBALj65laf8jiYuEhEpU1Hf24yMCg0mdky7d+9mxIgRrF69mtdee40777yzwnU0b96czp07M3PmTLKzs5kxY4anC8vQoUMJCgril19+8XRvKd7/HJwx38F5gPRY/7Efr+99VFQUqamp5OXlHXVs7969FX5dJ2rQoEF8++237N+/n7lz5/Loo4+yd+9eLr/8cn755Ref3ONE3rOuXbvyySefkJKSwu+//86zzz5LQUEBd911F++++65P4qpI7Hv27Cn1+O7du0ucV+Tqq69m3rx5pKSk8N1333H99dcza9YszjjjDJKSkjznled1FtXdp0+f8jSCepxzzjlMmzaN/fv3M3XqVO655x5WrVrFH/7wB1avXu2bN6iOq2yCng28W8ZS9J3LnMLy8bq/TC9cn26MKRGXMSYSGAIcBuZVMuZa6bohbfEr/NZp9oZ9rN1z0N2ARERqqKJuDe3atfNJfTt27GD48OGsXbuWN9980zMSxokYPXo0hw4d4o033uDAgQOeBD0sLIyBAwcyderUEl1fiit6gHP27NknfH9wkq2CggJ+/fXXo47NmTOnUnUXVzS6TX5+/jHPCw4OZvDgwTzxxBO88sorgPPwpS9U5j0LCAigb9++3H///UyePBmAL7/80nO8vK/vREVGRtK+fXt27tzJhg0bjjo+fbqTNiUklN5zt0GDBpx99tm8/fbbjBs3jtTU1FLfh2O9zoiICLp168aqVatITU2t8GsIDw9n1KhRvPDCCzz00EPk5OTwww8/VLie+qhSCbq19rC19obSFuDrwtPeL9z3CYAxJtAY06Vw1tDidW0CpgDxwG1H3OpxIBz4wFrruyaRWqRVozDO7O6duvqd2VtcjEZExF1lJQxbt27l9ttvB+DKK6+s9H22bdvG8OHD2bRpE++++y433XRTpeorahV/5plnSpSLtleuXMnXX39N48aNjxoB4/bbbycwMJB77rmH9euP/jI5JyenXIno1VdfDcAjjzxCTo53fo20tDT+9re/VfxFlaFomL5t27YddWz27NmkpR09JkRRC76vRnGp6Hu2YMGCUr9FKC2uY70+X7nuuuuw1vLnP/+5xAeBffv2eX5W1113nWf/jz/+WOo3I0Ut50XxV+R1/ulPfyInJ4frrruOAwcOHHXN/v37Wbx4sac8derUo8buL6tuKZtPZxItpxbAGmArTjJe3K3Ar8ArxpjRhecNAEbidG15uPrCrHluGNaO71c4X3V9tXQnfzmjM00KR3gREalPPv30U5599llGjhxJ27ZtiYyMZNOmTXz33XdkZWVx9tlnc999R09m/eyzz7J2rfPQ/dKlSwFnnOyiluOhQ4dyww03eM4fPnw4iYmJ9O3bt8whA8eNG1fumStHjhyJn58fSUlJdOnSpcTIIqNHj2b8+PEkJyczduzYox5K7NKlC++99x7XXXcd3bp148wzz6RTp07k5uaybds2Zs+eTWxsrOf1leXqq6/m448/5scff6R79+6MGTOG3NxcPv/8c/r168e6det8MorK6NGj+fTTT7nwwgs5++yzCQ0NpU2bNlx11VU8//zzTJkyhREjRtCuXTsiIiJYtWoVP/zwAw0bNqz0B6EiFX3PPvroI1577TWGDx9Ohw4daNiwIZs2beKbb74hODiYu+++21P3oEGDCAsL46WXXiI1NZWmTZsCcMcddxzV7aQsxxqe8fXXX+e+++7jhx9+4KuvvqJXr16cffbZZGZm8umnn5KUlMRf/vKXEg/2XnrppYSEhDB06FDi4+Ox1jJ79mwWLlxI3759OfXUUyv8Oq+77joWLVrE66+/Tvv27TnjjDNo3bo1qampbNmyhVmzZnHttdfy5ptvAnDvvfeSmJjIiBEjiI+PJygoiEWLFjFt2jTatGnDpZdeWq73pt47kY7r5Vko4yFRnKTcAollXNcKmADsBnJwEvmXgUY+iKlWPiRa3IWvz/U8LPr3H9e4HY6IuEAPiVo7Y8YMe+mll9rOnTvb6OhoGxAQYGNiYuypp55q33//fVtQUFDqdUUPLpa1HPmg47HOLVpKe3DyWAofHLO33nprif05OTk2PDzcAvb1118v8/rly5fba665xrZu3doGBQXZhg0b2m7dutmbbrrJTp06tdTXe6TDhw/bRx991MbHx9ugoCDbpk0b+9BDD3keCjzvvPNKnH8iD4nm5eXZBx980LZt29YGBASUePj0p59+suPGjbNdu3a1UVFRNiwszHbq1MnecccdNjExsew37xhKe0i0SHnfs3nz5tlbbrnF9uzZ0zZs2NCGhITY9u3b23HjxtkVK1YcVe8PP/xgBw4c6Pm5lXX/I5Xn92r//v3WWudn9dRTT9lu3brZkJAQGxERYYcMGVLqw7RvvPGGPf/8823btm1taGiobdiwoe3du7d97rnn7MGDB0/4dVpr7TfffGPPOeccGxsbawMDA23Tpk3tySefbB9++GG7Zo03H/nkk0/spZdeajt06GDDw8NtZGSk7datm33ooYdsUlLdGOSiOh4SNfaIjv11mTFmUUJCQsKiRWXNY1Tz/bhyN7dMcr5Kig4N5LcHRxEW5MYXISLilqIhzbp27epyJFLX/Pzzz5x++uk88MADnm44IlJSef8G9+3bl8WLFy+2ZQz/fSy+mqhIqslpJ8XRupHTfyvtcC6fL9rhckQiIlLb7Np19KR3KSkpPPDAAwBccMEF1R2SiBSjptdaxt/PcN2QeMZ/4wxT9O6cLVw+oA3+fpq4SEREyudPf/oTy5YtY/DgwcTGxrJjxw5++OEHUlNTufnmm0tMkCQi1U8Jei30x36teOHn9RzMyiMxJZNf1uzljG5xx79QREQEuPDCC9m7dy/ffPMNBw4cICQkhG7dunHdddeVeEhWRNyhBL0WCg8O4IqBbXhjxibAmbhICbqIiJTXxRdfzMUXX+x2GCJSBvVBr6XGDY4n0N/p1rIwcT9Ltx9wNyARERER8Qkl6LVU06gQzu3V3FN+Z/ZmF6MRERERqfuqa/RDJei12A1DvdNY/7ByDzv2Z7oYjYhUl6IJbAoKClyORESkfilK0I+cSMzXlKDXYic1j2JIB2eq4fwCy4S5ie4GJCLVIjg4GICMjAyXIxERqV+K/u4W/R2uKkrQa7kbhnlb0T9ZuJ2DWbkuRiMi1SEyMhKAPXv2kJ6eTkFBQbV97SoiUt9YaykoKCA9PZ09e/YA3r/DVUWjuNRyIzrF0rFJBBuSDnEoO4+PF2zjplPaux2WiFShRo0akZGRQWZmJjt2aLIyEZHqFBYWRqNGjar0HmpBr+WMMdwwrK2nPHFuIrn56pcqUpf5+fnRqlUrYmNjCQkJqfK+kCIi9Z0xhpCQEGJjY2nVqhV+flWbQqsFvQ44r3cL/vHTOvYdymFXWhbfr9jNeb1buB2WiFQhPz8/YmJiiImJcTsUERHxMbWg1wEhgf5cNTDeU35n9hb1RxURERGppZSg1xFXDmxNcIDz41yxM435W1JdjkhEREREToQS9DqicUQwF/Vt6Slr4iIRERGR2kkJeh1y/VDvw6K/rElic/IhF6MRERERkROhBL0OaR8bwaldm3jK787Z4mI0IiIiInIilKBXNWth1xL47l748cEqv931Q70TF322aAepGTlVfk8RERER8R0l6FVtzwr49whY+A4smgjZ6VV6u4HtGtG9RRQA2XkFTJq3tUrvJyIiIiK+pQS9qsX1gNiuznZuJqz6okpvZ4zhxmHeVvQPfkskKze/Su8pIiIiIr6jBL2qGQMJV3nLiz+s8lue3aMZzaJDANh3KIevl+6q8nuKiIiIiG8oQa8OPS8Bv0Bne8cCSF5XpbcL9Pfj2iHxnvI7czZr4iIRERGRWkIJenUIj4HOZ3nLS6q+Ff2Sk1sTHuQPwPq9h5i5PrnK7ykiIiIilacEvbr0KdbNZdnHkJ9bpbeLDg3kkpNbe8rvzNaQiyIiIiK1gRL06tJhNEQ2d7YzkmH9T1V+y2uHxONnnO05G/exetfBKr+niIiIiFSOEvTq4ucPvS/zlpdMqvJbtmoUxlk9mnnK78zZXOX3FBEREZHKUYJenXpf4d3eMAXS91T5LYsPufjNsl3sPZhV5fcUERERkROnBL06NW4PbYY62zYflk2u8lv2btWAfm0aApCbb3n/18Qqv6eIiIiInDgl6NWtz5Xe7SWToBqGP7yhWCv6f+ZvIzMnr8rvKSIiIiInRgl6dTvpPAiKdLZTNsK2eVV+y9NOakqbxmEApB3O5dPfd1T5PUVERETkxChBr25BYdDjIm+5GsZE9/czXD+0raf87pwt5Bdo4iIRERGRmkgJuhv6XO3dXvUFZKdX+S3H9m1JdKgzm+m21Ex+Xr23yu8pIiIiIhWnBN0NLRIgtquznZvpJOlVLCwogCsGFJ+4SEMuioiIiNREStDdYAwkFJtZdHHVd3MBuGZwPIH+zsxFv2/dz5Jt+6vlviIiIiJSfkrQ3dLzEvBzupywYwEkr6vyWzaNCmFMrxae8juzt1T5PUVERESkYnySoBtjnjPGTDXGbDfGHDbGpBpjlhhjHjPGNK5APYnGGFvGUvWz+lSn8BjofJa3XA0PiwLcMMz7sOgPK3ezPTWzWu4rIiIiIuXjqxb0e4Bw4GfgZeA/QB4wHlhujGlVgbrSgMdLWf7po1hrjj7Furks+xjyc6v8ll2bRTGsYwwABRYmzE2s8nuKiIiISPkF+KieKGvtUXPIG2OeAh4CHgRuLWddB6y1430UV83WYTRENof0XZCRDOt/gq5/qPLbXj+0LbM37APgk4XbuOvUjp4RXkRERETEXT5pQS8tOS/038J1R1/cp87x84fel3nLSyZVy22Hd4qlU9MIADJy8vl4wbZqua+IiIiIHF9VPyR6buF6eQWuCTbGXGmMecgYc5cxZqQxxr8iNzXGLCptAbpUpJ5q0fsK7/aGKZBe9V3tjTHcMLSdpzzx10Ry8wuq/L4iIiIicnw+TdCNMfcZY8YbY140xswG/oaTnD9bgWrigA+Bp4CXgGnABmPMcF/GWmM0bg9thjrbNh+WTa6W257XpzkxEcEA7E7L4rvlu6vlviIiIiJybL5uQb8PeAy4GxgK/Aicbq1NLuf1E4DROEl6ONADeAuIB34wxvQqTyXW2r6lLcDairyYatPnSu/2kklgbZXfMjjAn2sGtfGU35mzGVsN9xURERGRY/Npgm6tjbPWGpwE+0KgHbDEGJNQzusft9ZOs9butdZmWmtXWmtvAV4AQnFGhal7TjoPgiKd7ZSNsG1etdz2ioFtCAl0fgVW7jzIvM2p1XJfERERESlblfRBL0ywvwBOBxoDH1SyyjcL16dUsp6aKSgMelzkLVfTw6KNwoO4KKGlp/zO7M3Vcl8RERERKVuVPiRqrd0KrAa6GWNiKlFVUuE6vPJR1VB9rvZur/oCstOr5bbXD22LMc721LVJbEw6VC33FREREZHSVfUoLgDNC9f5lahjUOG67jbxtkiA2K7Odm6Gk6RXg3axEYzu0tRTfntW3X2LRURERGqDSifoxpguxpi4Uvb7FU5U1AT41Vq7v3B/YOE17Y84v5sxplEp9bQB/lVYrJ6+H24wBhKKzSy6+MNqu/VNp3iHXPxs8Q62pmRU271FREREpCRftKCfCWw3xkw1xvzbGPOMMeY9YAPOLKJ7gBuLnd8CWANMPaKePwK7jDE/GGNeN8Y8Z4z5DGfklQ7A98A/fRBvzdXzEvArnNFzxwJIXlctt+3fthGD2zcGIL/A8vLUDdVyXxERERE5mi8S9F+Af+M8DHoh8GfgIiAVeBzoZq1dXY56pgNfAG2By4E/AcOBOcA1wB+stTk+iLfmCo+Bzmd5y0uqrxX9T6d18mx/uWQnm5LVF11ERETEDZVO0AuHQrzNWtvbWhtjrQ2w1kZba0+21o631qYecX6itdZYa+OP2D/TWnuZtbaLtbaBtTbQWhtrrT3NWvuBrS+DdPcp1s1l2ceQn1stt+0X34hTOsUCUGDh5V/Uii4iIiLihup4SFQqosNoiCx8rjYjGdb/VG23Lt6K/s3yXazbUz0jyYiIiIiIlxL0msbPH3pf5i1X05joAL1bNWB0lyaAM5npy1PXV9u9RURERMShBL0m6n2Fd3vDFEjfU223vqdYK/r3K/awaldatd1bRERERJSg10yN20Oboc62zYdlk6vt1t1bRHNmN++omS/+rL7oIiIiItVJCXpN1edK7/aSSU6fk2py92kdPbOL/rJmL8u2H6i2e4uIiIjUd0rQa6qTzoOgSGc7ZSNsm1dtt+4SF8U5PZp5yi/+or7oIiIiItVFCXpNFRQGPS7ylqvxYVGAu0/thF9hK/qMdcks2rq/Wu8vIiIiUl8pQa/J+lzt3V71BWRX37CHHZpEcF7vFp7yCz9Xz6ymIiIiIvWdEvSarEUCxHZ1tnMznCS9Gt01uiP+hc3oczemMG9zSrXeX0RERKQ+UoJekxkDCcVmFl38YbXePj4mnIsSireir6e+TOgqIiIi4hYl6DVdz0vAL9DZ3rEAkqu3q8kdozoSUNiKvmBLKnM3qhVdREREpCopQa/pwmOg81ne8pLqbUVv1SiMi09u5Sm/8PM6taKLiIiIVCEl6LVBn2LdXJZ9DPm51Xr720d2IMjf+VVZvO0AM9YnV+v9RUREROoTJei1QYfRENnc2c5IhvU/VevtmzcI5bL+3lb0F9UXXURERKTKKEGvDfz8ofdl3nI1j4kOcNvIDgQHOL8uy3ek8cuapGqPQURERKQ+UIJeW/S+wru9YQqk76nW2zeJCuGqgW085Rd+Xk9BgVrRRURERHxNCXpt0bg9tBnqbNt8WDa52kO4ZUR7QgP9AViz+yA/rqreDwkiIiIi9YES9Nqkz5Xe7SWToJr7gcdEBHPN4HhP+cWf15OvVnQRERERn1KCXpucdB4ERTrbKRth27xqD+HmU9oRHuS0om9IOsS3y3dVewwiIiIidZkS9NokKAx6XOQtu/CwaMPwIK4b2tZTfvmXDeTlF1R7HCIiIiJ1lRL02qbP1d7tVV9Adnq1h3DD0HZEhgQAsHlfBl8uVSu6iIiIiK8oQa9tWiRAbFdnOzfDSdKrWXRYIDcOa+cpvzJ1A7lqRRcRERHxCSXotY0xkFBsZtHFH7oSxrVD4mkQFgjAttRMPl+0w5U4REREROoaJei1Uc9LwM9JjtmxAJLXVXsIkSGB3HSKtxX91Wkbyc7Lr/Y4REREROoaJei1UXgMdD7LW17iTiv6NYPiaRweBMDOA4f57+9qRRcRERGpLCXotVWfYt1cln0M+bnVHkJ4cAC3DG/vKb82bSNZuWpFFxEREakMJei1VYfRENnc2c5IhvU/uRLGlQPbEBsZDMCeg1l8NH+bK3GIiIiI1BVK0GsrP3/ofZm37MKY6AChQf7cNsLbiv76jE0czlEruoiIiMiJUoJem/W+wru9YQqk73EljEv7t6ZZdAgA+w5l8+G8RFfiEBEREakLlKDXZo3bQ5uhzrbNh2WTXQkjJNCf20Z28JTfnLmZQ9l5rsQiIiIiUtspQa/t+lzp3V4yCax1JYyL+7WiZcNQAFIzcnj/10RX4hARERGp7ZSg13YnnQdBkc52ykbYNs+VMIIC/LhzVEdP+d+zNnMwq/pHlhERERGp7ZSg13ZBYdDjIm/ZpYdFAS5IaEGbxmEApB3O5b05W1yLRURERKS2UoJeF/S52ru96gvITncljEB/P+4a7W1Ff3f2Fg5k5rgSi4iIiEhtpQS9LmiRALFdne3cDCdJd8l5vVvQLjYcgPTsPN6ZrVZ0ERERkYrwSYJujHnOGDPVGLPdGHPYGJNqjFlijHnMGNO4gnW1NMa8Z4zZZYzJNsYkGmNeMsY09EWsdZIxkFBsZtHFH7oWir+f4e5TO3nKE+ZuITVDregiIiIi5eWrFvR7gHDgZ+Bl4D9AHjAeWG6MaVWeSowx7YFFwLXAAuBFYDNwF/BbRZP9eqXnJeAX6GzvWADJ61wL5Q89mtG5qfPgakZOPm/N3ORaLCIiIiK1ja8S9Chr7UBr7XXW2gestXdYa08GngaaAw+Ws57XgSbAndba8wvrGoWTqHcGnvJRvHVPeAx0PstbXuJeK7qfn+Ge07x90d//LZHk9GzX4hERERGpTXySoFtrs8o49N/CdccyjnsYY9oBpwOJwGtHHH4MyACuMsaEn2CYdV+fYt1cln0M+e4Nc3j6SXGc1CwKgKzcAt6YoVZ0ERERkfKo6odEzy1cLy/HuaMK11OstQXFD1hr04G5QBgw8HgVGWMWlbYAXSoQe+3TYTRENne2M5JhwxTXQvHzM/zpNG9f9Enzt7InrazPcSIiIiJSxKcJujHmPmPMeGPMi8aY2cDfcJLzZ8txeefC9foyjm8oXHcq47j4+UPvy7xlFx8WBRjdtQm9WkYDkJNXwOszNroaj4iIiEht4OsW9PtwuqPcDQwFfgROt9Yml+Pa6MJ1WhnHi/Y3OF5F1tq+pS3A2nLEUbv1vsK7vWEKpO9xLRRjDPcUa0X/eMF2dh447Fo8IiIiIrWBTxN0a22ctdYAccCFQDtgiTEmwQfVm6Lb+KCuuqtxe2gz1Nm2+bBssqvhDO8US982zgiZOfkF/GvahuNcISIiIlK/VUkfdGvtXmvtFzgPfTYGPijHZUUt5NFlHI864jwpS58rvdtLJoF17zONMYZ7i7Wif/r7DralZLoWj4iIiEhNV6UPiVprtwKrgW7GmJjjnF40cHdZfcyLRoIpq4+6FDnpPAhyxiEnZSNsm+dqOIPaN2ZA20YA5BVYXlEruoiIiEiZqnoUF3DGQQfIP8550wvXpxtjSsRljIkEhgCHAXezzdogKAx6XOQtL5nkXiwUtqKf3tlT/t/iHWxOPuRiRCIiIiI1V6UTdGNMF2NMXCn7/YwxT+FMPPSrtXZ/4f7AwmvaFz/fWrsJmALEA7cdUd3jODOVfmCtzahszPVCn6u926u+gOx092IB+rdtxLCOzpcoBRZenqpWdBEREZHS+KIF/UxguzFmqjHm38aYZ4wx7+EMi/gQsAe4sdj5LYA1wNRS6roVSAJeMcZ8WVjXNOAenK4tD/sg3vqhRQLEdnW2czOcJN1lxUd0+XrZLjbsdfdDg4iIiEhN5IsE/Rfg3zgPg14I/Bm4CEjFafnuZq1dXZ6KClvR+wETgQHAvUB74BVgkLU2xQfx1g/GQEKxmUVdHhMdIKF1Q0Z2jgWc51Zf+kWt6CIiIiJHCqhsBdbalRzdJeVY5yfiHTKxtOPbgWsrG5cAPS+Bnx+DglzYsQCS10Fs5+NfV4X+dFpnpq9zhsX/bsVubtt1kJOaRx3nKhEREZH6ozoeEhW3hMdA57O85SXut6L3aBnNaSc19ZRf+kWD8oiIiIgUpwS9rutTrJvLso8hP9e9WAr9qVhf9Cmr97Jih4a2FxERESmiBL2u6zAaIgtHusxIhg1T3I0H6NosinN6NPOUX/h53THOFhEREalflKDXdX7+0Psyb7kGPCwKcNepHTGFTyJMX5fM4m373Q1IREREpIZQgl4f9L7Cu71hCqTvcS+WQp2aRjKmV3NP+cWf1RddREREBJSg1w+N20Oboc62zYdlk92Np9BdozviV9iKPnvDPhZsSXU3IBEREZEaQAl6fdHnSu/2kknOQOQuaxcbwYUJLT1l9UUXERERUYJef5x0HgRFOtspG2HbPHfjKXTnqI4EFDajz9ucyq8b97kckYiIiIi7lKDXF0Fh0OMib3nJJPdiKaZ14zD+2M/biv78z+uxNaB1X0RERMQtStDrkz5Xe7dXfQHZ6e7FUsztozoS6O+0oi/aup9ZG9SKLiIiIvWXEvT6pEUCxHZ1tnMznCS9BmjRIJRLT27tKb8wZZ1a0UVERKTeUoJenxgDCcVmFq0hY6ID3DayA0EBzq/jsh1pTF2T5HJEIiIiIu5Qgl7f9LwE/AKd7R0LILlmjJwSFx3ClQPaeMov/LyeggK1oouIiEj9owS9vgmPgc5necs15GFRgFtGtCMk0PmVXL37IFNWuz+hkoiIiEh1U4JeH/Up1s1l2WTIz3UvlmKaRIZwzaB4T/nFnzeoFV1ERETqHSXo9VGH0RDZ3NnOSIYNU9yNp5ibh7cnPMgfgHV70/l2xW6XIxIRERGpXkrQ6yM/f+h9mbdcgx4WbRQexLgh8Z7yS7+sJ1+t6CIiIlKPKEGvr3pf4d3eMAXSa05/7xuHtSMyOACAzckZfLV0p8sRiYiIiFQfJej1VeP20Gaos23znb7oNUSDsCCuH9bWU3556gZy8wtcjEhERESk+ihBr8/6XOndXjIJatDkQNcNbUt0qDMc5NaUTL5YrFZ0ERERqR+UoNdnJ50HQZHOdspG2DbP3XiKiQoJ5KZT2nnKL0/dQE6eWtFFRESk7lOCXp8FhUGPi7zlGjQmOsA1g+NpFB4EwM4Dh/nv79tdjkhERESk6ilBr+/6XO3dXvUFZKe7F8sRIoIDuLlYK/pr0zeSlZvvYkQiIiIiVU8Jen3XIgFiuzrbuRmw8n/uxnOEqwfFExMRDMDutCw+XrDN5YhEREREqpYS9PrOGEgoNrPor69Cfp578RwhNMifW0e095Rfm7GJQ9k1Jz4RERERX1OCLtD7cgiOdrZTNtSoIRcBLh/QmqZRTit6cno2j365EluDRpwRERER8SUl6AKhDWHIHd7yjGchN8u9eI4QEujPQ2d39ZS/WLKTzxbtcDEiERERkaqjBF0cA/4PwmOd7YM7YNEEd+M5wnm9WzC2b0tP+a9frWLD3przQKuIiIiIryhBF0dwBAy7z1ue9c8aNaILwBPndaN9bDgAh3Pzuf2jJRrVRUREROocJeji1e9aiG7lbGfug3lvuhvPEcKCAnjtigSCA5xf23V703n8m9UuRyUiIiLiW0rQxSsgGEY84C3/+gpkproXTym6xEXx2LndPOXJC7bx9bJdLkYkIiIi4ltK0KWknpdC447OdvZBmPuSq+GU5rL+rfhDz2ae8kP/W0HivgwXIxIRERHxHSXoUpJ/AIx62Fue/xYc3O1ePKUwxvDMhT1o0zgMgEPZedwxeQnZeeqPLiIiIrWfEnQ5WtfzoFkvZzsvC2b9w914ShEZEsirl/Uh0N8AsGJnGs/+sNblqEREREQqr9IJujGmsTHmBmPMF8aYjcaYw8aYNGPMHGPM9caYct/DGJNojLFlLHsqG6uUk58fjPqrt7z4fUjd7F48ZejZsgEPnuUdH33C3ESmrNKviYiIiNRuAT6o44/AG8BuYDqwDWgKXAi8A5xljPmjLf/Uj2nAS6XsP1T5UKXcOoyGNkNg61woyHMmL7rw325HdZRrh8Tz66YUflmzF4A/f7acbi2iadEg1OXIRERERE6ML7q4rAfGAC2ttVdYax+01l4HdAG2AxfhJOvldcBaO76U5Z8+iFXKyxgYXawVffl/YW/NG9LQGMM//9iT5tEhAKQdzuXOyUvIzS9wOTIRERGRE1PpBN1aO81a+421tuCI/XuAooG0R1T2PuKC1gOh4xmFBQvTnnQ1nLI0CAvi1cv74O/n9EdftHU/L/y83uWoRERERE5MVT8kmlu4zqvANcHGmCuNMQ8ZY+4yxow0xvhXRXBSDqMe8W6v+w52/O5eLMfQt00j7j29k6f8xoxNzFyf7GJEIiIiIiemyhJ0Y0wAcHVh8ccKXBoHfAg8hdMXfRqwwRgzvAL3XlTagtPtRiqiWU/ofpG3PPVx92I5jltOac+wjjGe8p8+WUrSwSwXIxIRERGpuKpsQX8W6A58b639qZzXTABG4yTp4UAP4C0gHvjBGNOrCuKU4xn5MBR9ibFlFmye4Wo4ZfHzM7x4SW9iI4MBSMnI4a6Pl5JfUN7nk0VERETcVyUJujHmTuBeYC1wVXmvs9Y+Xtinfa+1NtNau9JaewvwAhAKjC9nPX1LWwrjkYpq3B76XOktT30Cyj0oT/WKiQjm5Ut6Y5zu6Py2OYV/TdvoblAiIiIiFeDzBN0YcxvwMrAaGGmtTfVBtUUPm57ig7rkRAy/H/ydlml2LoK137kbzzEM7hDDHaM6esovT13PvM0pLkYkIiIiUn4+TdCNMXcD/wJW4iTnvpo1JqlwHe6j+qSioltA/xu95Wl/g4J89+I5jjtHdaB/20YAFFi46+MlpBzKdjkqERERkePzWYJujLkfeBFYipOcJx37igoZVLiuedNZ1idD74GgCGc7eS2s+NTdeI4hwN+PVy7tQ8OwQAD2Hszm3k+XUaD+6CIiIlLD+SRBN8Y8ivNQ6CJgtLV23zHODTTGdDHGtD9ifzdjTKNSzm+D0yoPMMkX8coJCo+BQbd7y9Ofhrwc9+I5jrjoEF64uLenPGNdMu/M0Wc8ERERqdkCKluBMeYa4AkgH5gN3GmKntDzSrTWTizcbgGsAbbijM5S5I/AA8aY6cAWIB1oD5wDhADfA5pN1G2DboMF/4bDqXBgKyx+v2TXlxpmZJcm3HxKO96a5STmf/9xHf3iG5HQuqHLkYmIiIiUrtIJOtC2cO0P3F3GOTOBicepZzrQGeiD06UlHDgAzMEZF/1Da2vo0CH1SUgUDPsTTCmcwGjWP6D35RBUcx8PuO+MzszfksrS7QfIK7Dc8dESvr9zGNGF3V9EREREapJKd3Gx1o631prjLCOKnZ9YuC/+iHpmWmsvs9Z2sdY2sNYGWmtjrbWnWWs/UHJeg5x8A0Q2d7YP7XVa1GuwQH8/Xr2sD5EhzufRnQcOc//ny9GvlIiIiNREVTlRkdRVgaEw/C/e8pyX4PABt6Ipl1aNwvjH2J6e8o+r9vDhvK0uRiQiIiJSOiXocmL6XAkNC3s3ZR2AX191NZzyOLN7M64e1MZTfvLbNazcmeZiRCIiIiJHU4IuJ8Y/EEY+7C3PewMO+XJkzarx0NldOalZFAA5+QXc/tFiDmXnuRyViIiIiJcSdDlx3S+CJt2c7dwMmP28u/GUQ0igP/+6vA/hQf4AJKZk8vAXK9QfXURERGoMJehy4vz8YPSj3vLv78GBbe7FU07tYiN46oIenvJXS3fx6e87XIxIRERExEsJulROpzOhZX9nOz8HZjznbjzldH6fFlzcr6Wn/NevV7J+b7qLEYmIiIg4lKBL5RgDo//qLS/7CJLXuRdPBYwf042OTSIAyMp1+qMfzsl3OSoRERGp75SgS+W1HQbtRznbtgCmP+VuPOUUFhTAa1ckEBLo/DNYv/cQj3+zyuWoREREpL5Tgi6+MapYX/TVX8GuJe7FUgGdmkYy/txunvLHC7fz1dKdLkYkIiIi9Z0SdPGNFgnQdYy3PPVv7sVSQZec3IoxvZp7yg/9bwVb9mW4GJGIiIjUZ0rQxXdGPQKm8Fdq01RInONuPOVkjOGpC7oT3zgMgIycfG7/aDHZeeqPLiIiItVPCbr4Tmxn6HWZtzz1Cagl44tHhgTyr8sTCPJ3/kms2nWQZ75f63JUIiIiUh8pQRffGn4/+AU629vnw4Yp7sZTAd1bRPPQ2V085Ym/JvLTqj0uRiQiIiL1kRJ08a2GbaDfdd7y1L9BQYF78VTQNYPjOf2kpp7ynz9dxo79mS5GJCIiIvWNEnTxvVPug0CnPzd7V8Cq/7kbTwUYY/jH2F60aBAKwMGsPO6YvITc/NrzIUNERERqNyXo4nsRTWDg/3nL05+C/Fz34qmg6LBAXrmsD/5+BoAl2w7wzym1Y/IlERERqf2UoEvVGHwHhEQ726mbYel/3I2ngvq2acifz+jsKb81czMz1iW5GJGIiIjUF0rQpWqENoQhd3vLM56D3MOuhXMibhrWjuGdYj3lP/13GXsPZrkYkYiIiNQHStCl6gy4GcKbONvpu2Dhu+7GU0F+foYXLu5Fk8hgAFIzcrjr4yXkF9SOoSNFRESkdlKCLlUnKBxO+bO3PPt5yDroXjwnoHFEMC9f2ofC7ujM25zKq9M2uBuUiIiI1GlK0KVq9R0HDVo724dTYd7rroZzIga1b8ydozt6yi9P3cCvm/a5GJGIiIjUZUrQpWoFBMGIB73lX/8FGSnuxXOC7hjVkYHtGgHO5Kh3f7yUfYeyXY5KRERE6iIl6FL1el4CMYUjouSkw5wX3I3nBPj7GV6+tA+NwoMASErP5t7/LqNA/dFFRETEx5SgS9Xz84dRj3jLC96GtJ3uxXOCmkaF8MLFvTzlmeuT+ffszS5GJCIiInWREnSpHl3PheZ9nO38bJj1d3fjOUEjOjfh5uHtPOV//LSORVv3uxiRiIiI1DVK0KV6GAOj/+otL/4QUja5F08l3Hd6Z/q0bgBAfoHlzslLSMusPTOlioiISM2mBF2qT7uRED/M2bb5MP1pd+M5QYH+frx6WR+iQgIA2HngMH/+bBnWqj+6iIiIVJ4SdKk+xsDox7zllZ/BnhXuxVMJLRuG8Y8/evujT1m9l/d/TXQvIBEREakzlKBL9Wp1MnQ+21ue9qR7sVTSGd3iGDc43lN++vu1rNyZ5l5AIiIiUicoQZfqN+oRoHBqzvU/wrb5roZTGQ+e3YXuLaIAyMkv4PaPFpOepf7oIiIicuKUoEv1a9oNevzRW576hDP7Ty0UHODPvy5LICLY6Y+emJLJn/67jLz8ApcjExERkdpKCbq4Y+SD4OcktWydA5umuRtPJcTHhPPUBd095Z9X7+X+z1doEiMRERE5IUrQxR2N2kHC1d5yLW5FBzivdwtuPsU7Pvrni3fwxLerNbKLiIiIVJgSdHHPKX+GgBBne/dSWPO1q+FU1gNndeHSk1t5yhN/TeTFn9e7GJGIiIjURkrQxT1RzaH/Td7ytCchP8+9eCrJGMNTF/TgnJ7NPPtembaRt2dtdjEqERERqW0qnaAbYxobY24wxnxhjNlojDlsjEkzxswxxlxvjKnQPYwxLY0x7xljdhljso0xicaYl4wxDSsbq9RAQ++BoEhne996WP6Ju/FUkr+f4cWLezOic6xn31Pfr+HjBdtcjEpERERqE1+0oP8ReBsYAMwHXgI+B7oD7wD/NcaY8lRkjGkPLAKuBRYALwKbgbuA34wxjX0Qr9QkYY1g8B3e8oxnIC/bvXh8ICjAjzeu6Ev/+EaefQ9+sYJvl+9yMSoRERGpLXyRoK8HxgAtrbVXWGsftNZeB3QBtgMXAReWs67XgSbAndba8621D1hrR+Ek6p2Bp3wQr9Q0g26FsMLPXmnbYdFEV8PxhdAgf94d148eLaIB5/nXez5ZyvR1SS5HJiIiIjVdpRN0a+00a+031tqCI/bvAd4sLI44Xj3GmHbA6UAi8NoRhx8DMoCrjDHhlY1ZapjgSBh2r7c86x+Qfci9eHwkMiSQ96/rT4cmEQDk5lv+b9IiFmxJdTkyERERqcmq+iHRoikVy/Pk36jC9ZRSkv10YC4QBgz0XXhSY/S7HqJaONsZyTD/zWOfX0s0Cg9i0vUDaNkwFICs3AKum7iQFTvSXI5MREREaqoqS9CNMQFA0UDXP5bjks6F67LGpdtQuO5UjnsvKm3B6XYjNVFgCAy/31ue+wpk1o2W5rjoECZdP4DYyGAADmXncc2EBWxMSnc5MhEREamJqrIF/VmcB0W/t9b+VI7zowvXZTUtFu1vUMm4pKbqfQU0au9sZ6fBr6+4G48PxceE8+H1/YkODQQgNSOHK99ZwPbUTJcjExERkZqmShJ0Y8ydwL3AWuAqX1VbuD7u1IzW2r6lLYXxSE3lHwCjHvaW570J6Xvci8fHusRF8f51/QkP8gdgz8Esrnx3PkkHs1yOTERERGoSnyfoxpjbgJeB1cBIa215+ykUtZBHl3E86ojzpC466QKI6+Fs5x2GWf90Nx4f692qAW9f04+gAOef3taUTK56dwEHMnNcjkxERERqCp8m6MaYu4F/AStxkvOKNH+uK1yX1ce8Y+Fac6fXZX5+MOqv3vKiibA/0a1oqsTg9jG8dnkC/n7Ol0Lr9qZzzYSFHMquvbOoioiIiO/4LEE3xtyPM175UpzkvKIDPk8vXJ9+5OyjxphIYAhwGJhXyVClput4GrQe5GwX5MKMZ92NpwqcdlJTnv9jL4qm8Fq2/QA3ffA7Wbn57gYmIiIirvNJgm6MeRTnodBFwGhr7b5jnBtojOlSOGuoh7V2EzAFiAduO+Kyx4Fw4ANrbYYvYpYazBgYXawVfdnHkLTGvXiqyPl9WvDEmG6e8q+bUrhj8hJy8wuOcZWIiIjUdQGVrcAYcw3wBJAPzAbuNEXNgl6J1tqJhdstgDXAVpxkvLhbgV+BV4wxowvPGwCMxOna8jBSP7QZDB1Og40/AxamPQmX/sftqHzuqkHxHMzK4x8/OT28fl69l798tpzn/9gLP7+j/h2JiIhIPVDpBB1oW7j2B+4u45yZwMTjVWSt3WSM6YeT8J8JnA3sBl4BHq/AA6dSF4x+tDBBB9Z+CzsWQcu+7sZUBW4b2YH0rDzenLkJgC+W7CQiOIAnzutGKR92RUREpI6rdBcXa+14a605zjKi2PmJhfviy6hvu7X2WmttM2ttkLW2jbX2LiXn9VCzXtDtAm952hPuxVLF7j+zM5cPaO0pfzhvK/+csu4YV4iIiEhdVZUTFYlU3siHwTjjhrN5Bmye6Wo4VcUYw9/O686YXs09+16bvsnTqi4iIiL1hxJ0qdliOkLvy73lqU+APe5cVbWSv5/h+Yt7MapLE8++Z39Yy0fzt7kYlYiIiFQ3JehS8w2/H/yDnO2dv8OcF9yNpwoF+vvx+hUJDGzXyLPv4S9X8PWyXS5GJSIiItVJCbrUfA1awcD/85an/g3Wfu9ePFUsJNCfd645mV4tnUl1rYU/fbKUaWv3uhyZiIiIVAcl6FI7jHwE2gwtLFj43411cmz0IhHBAUy8tj8dm0QAkFdg+b9Ji/ltU4rLkYmIiEhVU4IutUNAEFz8PjQoHOkk5xBMvhQy6+7gPg3Dg5h0wwBaNQoFIDuvgBveX8iy7QfcDUxERESqlBJ0qT3CY+DSyRAY7pT3J8Kn10B+rqthVaWmUSH85/qBNIkMBiAjJ59rJixg/d50lyMTERGRqqIEXWqXuO5w4Vve8pZZ8FPdnmC2deMwJt0wgIZhgQAcyMzlynfmsy0l0+XIREREpCooQZfap+u5zvjoRRa8BYsmuhZOdejUNJL3r+tPRLAz+W9SejZXvjufvQezXI5MREREfE0JutROp/wZTjrPW/7uPtj6q3vxVIOeLRvwzjX9CA5w/tluS83kynfmsz8jx+XIRERExJeUoEvtZAyc/wY07eGUC3Lhk6vgQN2e1Gdgu8a8cWUCAX4GgA1Jh7hmwgLSs+puP3wREZH6Rgm61F5B4XDZRxAW45Qz98HkyyEnw924qtioLk15/uJeGCdHZ/mONG54/3eycvPdDUxERER8Qgm61G4NWsMlk8DPeYCSvSvgy/9zZvepw87r3YInz+/uKc/fkspt/1lMbn6Bi1GJiIiILyhBl9qvzSA453lvefVXMOsf7sVTTa4Y0IYHzuriKU9dm8S9/11GfkHd/nAiIiJS1ylBl7qh7zXQ/2ZvefpTsOYb9+KpJrcMb89tI9t7yl8v28WjX63E1vFvEEREROoyJehSd5zxFLQ9xVv+382wZ6V78VST+07vzFUD23jKH83fxnM/rnMxIhEREakMJehSd/gHwh/fh4bxTjk3AyZfBhn7XA2rqhljeHxMNy7o08Kz782Zm3h9xkYXoxIREZETpQRd6pawRnDZxxAU4ZTTtsF/r4a8uj1WuJ+f4e9je3Jq16aefX//cR0fztvqYlQiIiJyIpSgS93TpCtc9A5QOA7h1rnw4/2uhlQdAv39+NflfRjcvrFn31+/WsmXS3a6GJWIiIhUlBJ0qZs6nwWjH/WWf38PFr7jXjzVJCTQn39f3Y/erRoAzmiT9366jJ9X73U3MBERESk3JehSdw39E3S/yFv+4X7YMtu9eKpJRHAAE689mc5NIwHIL7Dc9tFift1Yt/vii4iI1BVK0KXuMgbG/Aua9XbKBXlOf/T9iW5GVS0ahAXx4fX9adM4DICcvAJu+OB3lmzb73JkIiIicjxK0KVuCwqDSz+C8CZO+XCqM7JLdrq7cVWDJlEhTLp+AHFRIQBk5uQzbsJC1u2p+69dRESkNlOCLnVfdAu49D/gH+SUk1bDF7dAQYG7cVWDVo3CmHRDfxqFO6897XAul709jzdnbuJAZt0e2UZERKS2UoIu9UOr/vCHF73ltd/CjGfci6cadWgSyQfX9ScyOACA1Iwcnv1hLQOfmcqD/1vB+r1qURcREalJlKBL/dHnShh4m7c86++w6gv34qlG3VtE8961JxMTEezZl5VbwOQF2zj9xVlc8c48fl69l/wC62KUIiIiAkrQpb457QloP8pb/uL/YPcy9+KpRifHN2LO/SP5+9iedG0WVeLY3I0p3PjB74z85wzemb2Zg1m5LkUpIiIiStClfvEPgLHvQaP2TjnvMEy+HA4luRtXNQkJ9Ofifq34/s6hfHLTQM7qHoef8R7flprJk9+tYeDTU/nrVyvZlHzIvWBFRETqKSXoUv+ENoTLPobgwlbkgzvgk6sgr/48NGmMYUC7xrxxZV9m/WUkNw9vR3RooOd4Zk4+H/y2ldHPz+Sa9xYwfV0SBer+IiIiUi2UoEv9FNsJLnoXKGw+3j4PvvuTM/VmPdOyYRgPntWVeQ+O5pkLe9CpaUSJ4zPXJ3PthIWc+sJM3v81kUPZeS5FKiIiUj8oQZf6q9PpcNrj3vKSD2HBv92Lx2WhQf5c1r81P919Ch/dMIDTTmqKKdb9ZfO+DB77ehUDn57K49+sInFfhnvBioiI1GEBbgcg4qrBd8LeVbD8E6f844MQ2xnajXA1LDcZYxjcIYbBHWLYlpLJB78l8snv20nPclrOD2XnMWFuIhN/TWRU5yaMGxLP0A4xmOLZvIiIiJwwtaBL/WYMnPsKtOjrlG0+/PcaSN3sblw1ROvGYTzyh5OY9+Bo/nZeN9rFhnuOWQtT1yZx1bsLOO3FWUyat5XMHHV/ERERqSwl6CKBIXDJfyAizilnHYDJl0HWQVfDqknCgwO4alA8v9wznPev68/IzrEljm9MOsQjX65k4NNTefr7NWxPzXQpUhERkdpPCboIQFQzuPQj8C+cyCd5LfzvRijIdzeuGsbPzzC8UywTru3PtHuHM25wPOFB/p7jB7Py+PeszQz/x3Ru/vB3ftuUgq2HD96KiIhUhk8SdGPMWGPMq8aY2caYg8YYa4yZdAL1JBZeW9qyxxexipSpZV8Y86q3vP5HmPake/HUcO1iIxg/phvzHhrNY+eeRHzjMM+xAgs/rdrLZW/P46yXZ/PJwm1k5erDjoiISHn46iHRR4BewCFgB9ClEnWlAS+Vsl8zpkjV63UJ7F0Jv77ilOe8AE27QY+x7sZVg0WGBHLtkLZcMyieGeuTmDA3kdkb9nmOr92Tzv2fr+CZH9ZyWf/WXDWwDc0bhLoYsYiISM3mqwT9HpzEfCMwHJheiboOWGvH+yIokRNy6nhIWgMbf3bKX90GjdtD8z6uhlXT+fkZRnVpyqguTdmwN533f0vk80U7OVzYcn4gM5c3Zmzi37M2c2a3OMYNiadfm4Ya/UVEROQIPuniYq2dbq3dYNXZVOoCP38Y+y407uiU87Jg8uWQvtfduGqRjk0jefL8Hsx7cDQPn92Vlg29Leb5BZbvVuzmj2/+xrn/msNni3ao+4uIiEgxxtc5tTFmBE4L+n+stVdW8NpEIBj4M9AayACWA7OsteX+H9wYs6iMQ10SEhLCFi0q67BIMfs2wjujICvNKbc8GcZ9BwHB7sZVC+UXWKau2cuEuYn8tjnlqOONw4O4YkBrrhjYhqZRIS5EKCIi4lt9+/Zl8eLFi621fSt6bU0cxSUO+BB4Cqcv+jRggzFmuJtBST0U0wHGTgBT+M9kx0L49h5nAHCpEH8/w+nd4ph800B+vHsYl/VvRXCA989PSkYOr0zbyJBnp3Hn5CWs2JHmYrQiIiLuqmkJ+gRgNE6SHg70AN4C4oEfjDG9ylOJtbZvaQuwtorilrqqw2g4vdhILkv/A/Nedy+eOqBLXBTPXNiTeQ+O5v4zu9A82ttinldg+XrZLs791xyufm8B80tpbRcREanralSCbq193Fo7zVq711qbaa1daa29BXgBCAXGuxuh1EsDb4XeV3jLUx6BjVPdi6eOaBgexP+NaM+sv4zk9SsS6B/fqMTxWeuTueTf8/jjm78yY12SxlMXEZF6o0Yl6MfwZuH6FFejkPrJGPjDi9Cyv1O2BfDZtU4fdam0AH8/zu7RjP/eMohv7xjKub2a41dsYJeFifsZN2Eh5/5rDj+s2E1BgRJ1ERGp22pLgp5UuA53NQqpvwKC4ZJJENXCKWelweRLvQ+Qik90bxHNq5f1Yeq9I7ikXysC/b2Z+sqdB/m//yzmtBdn8vmiHeTmF7gYqYiISNWpLQn6oML1ZlejkPotsilc+h8IKOwznbIBPrseCjREoK+1jQnnubE9mfnnkYwbHE9IoPdP1abkDO79dBkj/zmDD+dt1RCNIiJS51R7gm6MCTTGdDHGtD9ifzdjTKNSzm8D/KuwOKk6YhQpU/M+cN5r3vLGn+GX8a6FU9c1bxDK+DHdmHP/KG4d0Z7IYO/cajv2H+bRL1cy7O/T+fesTWRk57kYqYiIiO/4ZBx0Y8z5wPmFxTjgDJzW7tmF+/ZZa+8rPDce2AJstdbGF6tjPPAAzhjqW4B0oD1wDhACfA9cYK3NqUScixISEhI0DrpU2tQnYPbz3vIFb0GvS92Lp55IO5zLh78l8u6cLezPzC1xrEFYIOMGxzNucDwNwoJcilBERMRRmXHQfZWgjwceO8YpnmT8GAn6cOAWoA/eYRYPAEtxxkX/sLIzlSpBF58pKICPL4f1Pzhl/2C49gdoWeF/g3ICMnPy+Gj+Nt6evZm9B7NLHAsP8ufKQW24fmhbmkRq0iMREXGH6wl6baEEXXwq6yC8exokFw6vHxEHN82AqGauhlWfZOfl8/minbw5cxPbUjNLHAsO8OOSk1tx0yntaNkwzKUIRUSkvqprM4mK1A4hUXDZZAhp4JQP7XFa1XMPuxpWfRIc4M/lA1oz7d7hvHRJbzo1jfAcy84r4IPftjLiHzO479NlbEo+5GKkIiIi5acEXaQyGrWDi98H4++Udy2GyZdBxj5346pnAvz9OL9PC3686xTeuqovPVtGe47lFVg+W7SDU1+YyW3/WcyqXRoaU0REajYl6CKV1W4EnPmst7x5Orw5DLbNdy2k+srPz3BGtzi+um0IH17fnwFtvQNDWQvfrdjNOa/M4doJC1i0NdXFSEVERMqmBF3EF/rfCMMf8JbTd8HEs+HXV53MUKqVMYZhHWP55OZBfHbLIEZ2ji1xfPq6ZC564zcuees3Zm9Ipj49iyMiIjWfEnQRXzAGRj4Il38KoQ2dfQV5MOUR+PgKOHzA1fDqs37xjZhwbX++u3Mo5/RohvFOTsr8Lalc9e4Czn9tLj+t2kNBgRJ1ERFxnxJ0EV/qdDrcPBta9PPuW/cdvHUK7FriXlxCt+bRvHZFAj/fM5yxfVsS4OfN1JftSOPmDxdx5suz+HLJTvLyC1yMVERE6jsl6CK+1qCVMyb6wFu9+w5shXdPh4XvqMuLyzo0ieCff+zFjD+P4OpBbQgK8P4ZXL/3EHd/spRRz8/ko/nbyM7LdzFSERGpr5Sgi1SFgCA48xm4+AMIjnL25efAd/fC59dDdrq78QktG4bxxHndmXP/SG4e3o7wIH/PsW2pmTz0xQqG/30G787ZQmZOnouRiohIfaMEXaQqnXSeM3lRXA/vvpWfw79Hwt5VroUlXk0iQ3jwrK7MfWAUd5/akejQQM+xPQez+Nu3qxn63HT+NW0DaYdzXYxURETqCyXoIlWtcXu4/mfoO867L2UDvD0alvzHtbCkpAZhQdx9aifmPjCKh87uQmxksOdYakYO/5yynqHPTuPvP65l36FsFyMVEZG6ztSn4cWMMYsSEhISFi1a5HYoUl8t+wS+vRtyi01L3+dKOOsfEKTp6GuSrNx8Pl20gzdnbGLngZKzwwb4Gfq0bsCQDjEM7RBDr1YNCPRXe4eIiHj17duXxYsXL7bW9q3otUrQRapb0lr479Wwb513X5NuTn/1mA7uxSWlys0v4Oulu3h9xkY2JWeUek54kD8D2jVmSIcYhnRoTOemkZji4zmKiEi9owS9nJSgS42RkwHf3gPLP/HuC4qAMa9C9wvdi0vKVFBg+WnVHt6atZml2w8c89yYiGCGdGjMkPYxDOkYQ4sGodUTpIiI1BhK0MtJCbrUKNbC4vfh+79AfrE+zf1vgtOfhIDgsq8VV+07lM2vm1KYu2EfczbuO6oLzJHaxoQzuH1jhnaIYVD7xjQIC6qmSEVExC1K0MtJCbrUSLuXO11e9m/x7mveB/44ERrGuxWVlJO1lm2pmczdmMLcjfuYu2kfBzLLHu3FGOjePNrTHebk+EaEBPqXeb6IiNROStDLSQm61FhZafDV7bDma+++kGg4/03ocrZ7cUmFFRRYVu8+yNyNTuv6wsRUsnLLnpk0KMCPfm0aFibsMfRoEY2/n/qvi4jUdkrQy0kJutRo1sL8N2HKI1BQbGKcwXfC6L+Cf2DZ10qNlZ2Xz+KtBzyt68u2H6DgGH92o0ICGNiuMUM7xjC4fQztY8P1wKmISC2kBL2clKBLrbB9IXw6Dg7u8O5rPQjGvgdRzV0LS3zjYFYu8zenelrYNyYdOub5cVEhnu4wQzrE0DQqpJoiFRGRylCCXk5K0KXWyEyFL26GDVO8+8Iaw0XvQPtR7sUlPrf3YJYnWf91Ywp7DmYd8/yOTSI83WEGtGtEVIi+WRERqYmUoJeTEnSpVQoKYO6LMO1JsEV9mA0Mvx+G/wX89GBhXWOtZVNyBr9u2secDfv4bXMK6Vl5ZZ7v72fo2TKaoR2c7jAJbRoQHKDfCxGRmkAJejkpQZdaKXEOfHYdHNrr3dd2uNOaHtHEvbikyuXlF7ByV+EDpxv2sWjrfnLyy37gNCTQj/5tGzOkfWP6tmlIl2ZRRAQHVGPEIiJSRAl6OSlBl1rrUBJ8fj1smeXdFxHn9EuPH+JeXFKtDufk8/vWVM+Qjit3pXG8P+FtGodxUrMoujaLctbNo2geHaIHT0VEqpgS9HJSgi61WkE+zHgWZv0DKPx3a/xh9KMw+C7w83M1PKl+BzJz+G1TitN/fVMKW/ZllOu66NBAb9LePIquzSLp2CSSoAD9DomI+IoS9HJSgi51wsZf4H83QWaKd1+nM+H8NyCskXtxiet27M/k140pzNuSwupdB9mYdIi8Y43pWEygv6FDk0i6NovkpMLE/aRmUZr1VETkBClBLycl6FJnpO2Ez66F7fO9+6JbwR/fh5YV/jsgdVR2Xj4b9h5ize6DrN59kNW7DrJm90EOHuPB0yM1jw7xtLQXtbq3bhSGnyZTEhE5JiXo5aQEXeqU/Fz4ZTz89i/vPr9AOOMp6H+TM6e8yBGstew8cLgwWU9n9e401uxOZ1tqZrnrCA/yp0thn3ani0wUnZtGEhqkEWRERIpUJkHX4/0itZV/YTLeZjB88X+QnQYFufDDX2DrXBjzKoREux2l1DDGGFo2DKNlwzBO7xbn2X8wK5e1u9Od1vZdB1mz5yBr96STk3f0qDEZOfks2rqfRVv3e/b5GWgbE85JzaMLW9ojOal5FE0iNbGSiEhFqQVdpC5I3eLMPrp7qXdfo3ZOl5dmPd2KSmq5vPwCNu/L8CTtRd1kUjJyyl1HTESwJ1k/qbDVvW1MOAH+eiBVROo2dXEpJyXoUqflZsGUh2HhO959/sFw9j8g4Wp1eRGfsNaSnJ7tJOvF+rVv3pdx3CEfiwQH+NE+NoImUcE0Dg8mJiKIxhFBNA4PpnFEEDERwcREBNMoPEgjy4hIraUuLiICgSFwzvPQehB8fSfkZkB+NnxzJ2z9Ff7wAgSFux2l1HLGGJpEhdAkKoQRnb0TZWXm5LFuT3qJfu1rdh8kMyf/qDqy8woKE/zj3y8qJICYiOASCXzjCCepj4kIpnG4txwVEqiHV0WkTlCCLlLX9BgLcT3h02sgabWzb/nHTveXiz+A2M6uhid1U1hQAH1aN6RP64aefQUFlq2pmd5+7YWt7rvTsspd78GsPA5m5bG5HGO8B/gZGhVL2BuHFybxEUUt8yVb6UMC9VCriNRMStBF6qLYTnDDVPjuXlj2kbMveS38e6TzYOlJ52nMdKlyfn6GtjHhtI0J5+wezTz7UzNy2JqSQWpGDimHctiXkc2+9BxSMrKd8qFsUjJySM3IIb+c47gD5BVYktKzSUrPLtf54UH+xZL34BIJfOOIYFo1DKVT00jCg/VfpYhUL/3VEamrgsLggjecUV6+vw/yspxuL9/eDd/eA027Q9thED8M2gyC0IbHrVLEFxqFB9Eo/PgTIBUUWNIO55KSkU1ysQQ+5VA2+zKcdcqhHFIynKQ+vQLju4MzGk1GauZxh5hs3SiMznGRdImL9KzjG+tBVxGpOnpIVKQ+2LMS/ns1pG4q4wTjjPYSXyxh1xCNUstk5eaXaJUvSuaLEvh9h4on9dnk5p/4/39BAX50iI3wJO1O4h5F06hgjB7IFhH0kKiIHE9cd7hpBvz2Gmz8BXYtAVv84T0Lu5c5y2//AuMHzXpB/FCIPwVaD4SQKLeiFymXkEB/mjcIpXmD0OOea63lYFaeJ4FP8STwTjKfnJ7NpuRDbN6XUWo3mxzPg64HS+yPDg08qrW9U9NIIkMCffY6RaTu80kLujFmLDAc6A30AiKB/1hrrzyBuloCTwBnAo2B3cCXwOPW2v3HuLQ8dasFXQQg6yBsnw9bZkHibCcxt0dPSONh/KF572IJ+wAIjqy2cEXckp2Xz6akDNbuOci6Pems3ZPOuj3p7DlY/gddAVo0CKVLXCRdmkXSOS6KLnGRtI0JJ1DdZETqLNfHQTfGLMVJzA8BO4AunECCboxpD/wKNAG+AtYC/YGRwDpgiLU2pRJxKkEXKU1WGmz9zUnWE2fD7uXAMf42GH9okVDYJWao08KuIRylHknLzHWS9r3epH3dnnQOZZe/H3ygv6G9p5tMlKfVvVl0iLrJiNQBNSFBH4mTmG/EaUmfzokl6D8BpwN3WmtfLbb/BeAe4C1r7S2ViFMJukh5HD7gjJ2eOAcSZzl92I+VsPsFQIu+3oS91QDnIVWResRay84Dh0u0tK/bk86m5EPkVWA0mqiQAE+/9qLEvVPTSKJD1U1GpDZxPUEvUaExIziBBN0Y0w7YBCQC7a31ft9ujInE6epigCbW2uMPiFv6PZSgi5yIzNRiCfts2Lvy2Of7BULLfsUS9v4QePx+wSJ1UU5eAZv3HfJM5LSusLvMrgqMBw/QPDrkqKS9WXQIDcIC1eIuUgPVlYdERxWupxRPzgGstenGmLk4resDganHqsgYU1YG3qXSUYrUR2GNoOsfnAWchD1xjjdhL5oQqUhBLmz7zVlm/R38g6BlfydZbzsMWvRzZj4VqQeCAvzoEhdFl7gozuvt3Z92OJf1ni4y3j7uZQ0XuSsti11pWUxfl1yyfn8/YiODaRIVTJPIYJpEhjjrKGe76Fjj8GD8NdOqSK1QkxL0oukN15dxfANOgt6J4yToIlLFwhrBSWOcBSBjX8mEPXltyfPzc2DrHGeZ+SwEhEDLk50W9rbDnO4xAcHV/zpEXBQdGsjJ8Y04Od47aZi1lt1pWcW6yRxkbWE3mbKGhczJL2DngcPsPHD4mPfz9zPERASVSOBji7Yjg2kS5WzHRgbr4VURl9WkBL1o0OW0Mo4X7W9wvIrK+iqhsGU9ocKRicixhcdAt/OdBeBQkjdZT5wD+4743J2X5X0gdQYQEOp0gylK2FueDH6ahl3qH2OMZ6jIkV2aePbn5hewZV+GN2nfnc7mfRkkHcwiIyf/GDV65RdY9h7MZu/B48+02ig8qETSfmQS3yQyhCZRwYQE6t+pSFWoSQn68RR9L1d/ZlYSqa0imkD3C50FIH1PyYQ9ZWPJ8/MOw5aZzjIdiOkEIx6Aky4AP7XkiQT6+9GpqdPvnF7NSxzLyM4jKT2bpINZzjo9m6T0LJIPereT0rM5kJlb7vulZuSQmpHD2j3pxzwvMiSAJpHBNC1K3Iu1wjeJDKFlw1BaNAjFT11rRCqkJiXoRS3kZU1fGHXEeSJSW0TGQY+xzgJwcBckznVGiEmcA6mbS56/bz18dh00eR5GPghd/gB6CE6kVOHBAbQNDqBtzLGHOs3KzSe5MIFPLkzakw56E/ikwoQ+JSOb8o4fkZ6VR3pWHpuSyx67ITjAj/axEXRoUnKJbxxOUIA+gIuUpiYl6OsK153KON6xcF1WH3URqS2imkPPPzoLQNoOb8K++mvILpydMWkVfHKlM6vpyEeg42lK1EVOUEigP60ahdGq0bGHQM3LLyAlI8eTvO89IokvSu6T07PLNXxkdhmzrvr7Gdo0CqN9kwg6Fkvc28dGEB5ck9ITkepXk4ZZbI8zjnoiZQ+z6AfEaphFkTosMxV++xfMexNyj/in3vJkGPkwtBuhRF3EZQUFlv2ZOd5uNQe9ifvewu2tKRnsO5RT4bqbR4fQvljS3rFJJB2aRNAoPKgKXolI1ahVwywaYwKB9kCutXZT0X5r7SZjzBSckVpuA14tdtnjQDjOREUnlJyLSC0R1ghG/xUG3gpzX4IFbzsPlQLsWAgfng9thsKoh6HNYDcjFanX/PwMjSOCaRwRTNdmZZ93IDOHjUmH2Jh0iA2F641Jh4456kzRkJKzN+wrsb9ReBAdYiNKJO8dmkTQXLOvSh3jq5lEzwfOLyzGAWcAm4HZhfv2WWvvKzw3HtgCbLXWxh9RT3vgV6AJ8BWwBhgAjMTp2jLYWptSiTjVgi5S26TvgdkvwKIJznCNxbUbCaMecSZFEpFaJTMnj83JGZ6EfWPSITYmHyJxX0aFZl4FCAvyd5L1I5L3No3CCNCQkeIS12cSNcaMBx47ximeZPxYCXrh8VbAE8CZQGOcri1fAo9ba1MrGacSdJHaKm0HzPonLPkQCo6YyKXTmTDyIaevuojUarn5BWxNOTpx35SUweHc8g0pWSTQ3xDfOLywm4w3eW8fG6EhIqXKuZ6g1xZK0EXqgNQtMOsfsGwylJx0GLqOcRL1Jl3diU1EqkxBgWVX2uGSiXth8l6RISTBeYSlZcNQOsRG0Ckuks5NI+kc5/RzDw5Q4i6+oQS9nJSgi9Qh+zbAjGdh5eeUnB7BQPeLYMSDENPBrehEpJpYa0nJyCmRtG9Kdta707IqVJe/n6FtTDidiyXtXeIiadUwTGO5F8ornLl2874MtiRnsH1/JjERwfRsGU2PFtE0CNODvEWUoJeTEnSROmjvapjxDKz5uuR+4we9LoPhf4GG8a6EJiLuSs/KZdMR/dw3JR9ia0oGFenmHhroT6emEU7iHhflSd5jI4OrLngXWWtJSs9mc3IGW/ZlsGXfocJ1BttSM8nNL/vNa9M4jB4togsT9gZ0bxFFZEhgNUZfcyhBLycl6CJ12O5lMP1pWP9jyf1+AdDnSjjlzxDd0p3YRKRGyc7LJ3FfJhuS0lm3p3DZm8621MxyT9IE0Dg8iM5xzgyvXeIiPdu1ZRz3tMO53gQ8OcNpFS9cMnMq1t+/LMZAu5hwerZs4EncuzWPJjSo7nclUoJeTkrQReqBHb/D9Kdg07SS+/2DoO+1MOxPzsymIiJHyMzJY/3eQ6zbc5B1ew6xbu9B1u1Jr/BY7q0ahdK5aRRd4iLpVNhNpm1MOIEujCiTlZvP1pRMtuw75OmWUpSEp2RUfIx6gCaRwbSNCaddbDgtG4ax68BhVuxMY83ug8dsXS/iZ6BT00hPwt6zZQO6NIusc/3/laCXkxJ0kXpk668w7SnYOqfk/oBQ6H8DDLkbwmNcCU1Eapd9h7JZvyedtYWt7Wv3prNhb3qFWpkD/Q3tY4u6yThJe6emkbRoEFrpMdyP7Be+pVhL+K60wxX6VqBIZEgA7WIjaBcTTttiS3xMOBFlfEOQnZfPuj3pLN+RxoodaSzfmcb6venkl6M/UaC/oXNcJD1aNChM2qPp1DTSlQ81vqIEvZyUoIvUM9bClplOor5jQcljgeEw8BYYfAeENnQnPhGptQoKLDv2H2btnoOeLjLr9qSzeV9GuRLSIpHBAc5IMkc8mHrkw5bWWpLTs0t0Q3H6iB86br/wsgQF+NG2cWHyHeusixLyRuFBPpn8KSs3n1W7DrJixwGW73QS943Jh8r1oSEowI+TmkV5Wtl7toymfWwE/rXkgV0l6OWkBF2knrIWNvwM0590+qoXFxwNg26Dgf8HIVHuxCcidUZ2Xj6bkjIKu8cUdZdJZ1cFR5RpGhVMp6aRRIcGkpjitIxnnEC/cD8DLRuGeVrA28V6W8ObR4e6MjrNoew8Vu1MY8XONKe1fWcaW/aVb6L40EB/ureIokeLBvRq5YwcE984vEaOsqMEvZyUoIvUc9bC2u+cPupJq0seC20IQ+6C/jdBULg78YlInZV2OJcNe73dZNbtSWftnoMczMo7/sXlULxfuJOAR9A2JpxWjUJrRd/utMxcVu4qStgPsHxHGjv2Hy7XtZHBAXRvEU3PVtH0LOwi07Jh5bsOVZYS9HJSgi4iABQUwOovYPozkLKh5LHwWBh6D/S7DgJD3YlPROoFay17D2Yf1U1mQ9IhcvIKjjo/MiSgWJ/wCNrGOl1SjtUvvDZLOZTNip3e/uwrdqSx52D5voloEBZIjxbR9GrZgB6FfdrjokKqNWlXgl5OStBFpIT8PFjxKcx8FvYnljwW2QyG3QsJV0NA3RzrWERqprz8AhJTMlm3J53MnDziC5Pyxj7qF16bJR3MYrknYXda2sszGk1wgB8rHz+jWh86rUyCXvc+bomIlJd/APS+DHqMhaUfwax/QNp251j6bvj+Ppj7sjOGeu/Lwb9+TrYhItUrwN+PDk0i6NAkwu1QapwmUSGcelIIp57UFHC+hdiVluVJ1ov6tacdzi1x3UnNo2rViDBK0EVE/AOh7zXQ61JY/AHM+icc2uMcS9sO39wJc16EEQ9Ajz+CX83vzykiUh8YY2jRIJQWDUI5s3szwEnat6VmFkvYD9Cnde0arUtdXEREjpR7GH5/D2a/AJn7Sh6L6eSM+BLRFALDICgCgsIKt8OdJSAU/GpPS42IiPieuriIiPhSYKgz9GLCNbDg3043l6wDzrF96+Hbe8pRR2HCXjxx98W2f5Azd7aIiNRZStBFRMoSHAHD/gQnXw/z3oDfXoPsg+W7NjfTWXzNL8CZZCnoWB8AIiCuO3Q4DaJb+D4GERGpUkrQRUSOJyTa6X/e/yan60vSasjJhNwMZ52TUXI7r3xj956QgjzITnOW8mjSDTqe5iytBuhBVxGRWkAJuohIeYU1glPuO/55BQVO6/mRiXultzOcBL0iklY5y9yXIDgK2o2AjqdDh1MhqtmJvAsiIlLFlKCLiPian5/TPSa4CoZIy8s5fkKfkQSbZ8DWXyG/2PjA2QdhzdfOAhDXw0nWO54OLfo5w06KiIjr9NdYRKQ2CQhyltDjDBk29B7IPgRbZsGGKbDxF+8Y70X2rHCW2c873Xjajy5sXR8NEU2q7jWIiMgxKUEXEamrgiOgy9nOYi0kr4UNPzsJ+7bfSnaXyUqDVf9zFoDmfZyHTDueDi0SNPa7iEg1UoIuIlIfGANNujrLkDsh6yBsmekk6xt+gfRdJc/ftcRZZv0dQhs5reodT3da2cMbu/MaRETqCSXoIiL1UUgUdD3XWayFvatg489OC/u2eWDzveceToUVnzoLBlr0Ley7fio066NJmUREfEwJuohIfWeMM256XHen7/rhA85Dpht+dpL2Q3uLnWxh5+/OMuNpCItxhnDscCq0H+WMdCMiIpWiBF1EREoKbQDdzneWggLYu8LbFWbHArAF3nMz98Gyyc5i/KDlyYXjrp8OcT0166mIyAlQgi4iImXz84NmvZzllD9DZipsnl7Yuv4LZCR7z7UFsH2+s0x7EiKaFj5oeiq0G+kk/iIiclxK0EVEpPzCGkH3i5yloAB2L/V2hdnxO2C95x7aC0snOYvxh9YDna4wHU+Hpt3Uui4iUgYl6CIicmL8/JwhGFskwIj7ISMFNk31tq4fTvWea/Nh61xnmfq407re5CSI6QQxHQvXnSAyTom7iNR7StBFRMQ3whtDz4udpSDfGaZxwxQnYd+1uOS5h/Y6y+bpJfcHRRZL2Isl7o3aORM0iYjUA0rQRUTE9/z8oWU/Zxn5EBxKLmxdnwIbp0LWgdKvy0l3kvkjE3rjDw3jvYl7bGdnu3EHjRwjInWOEnQREal6EbHQ61JnKciHlE2QsgH2rYd9GyB5nbPOTiv9epsPqZucZf0PJY+Fxx7d4h7TEaJbaQZUEamVlKCLiEj18vOH2E7Owjne/dbCoaTCpL0wcS9ap20ru76MZGfZOrfk/oAQp4X9yMS9cQcICq+SlyYi4gtK0EVEpGYwBiKbOkvbYSWP5WRCysajE/eUDZCXVXp9eVmwd6WzHCm6Vel93SOa6iFVEXGdEnQREan5gsKgWU9nKa6gANK2F0vaiyXwGUll15e23Vk2TSu5PzjKm7A3agcN2kCD1s4SGacuMyJSLZSgi4hI7eXnBw3bOEvHU0seO7wf9hW1uq/zJu6pW5w+7aXJPgg7FznLUfcKhOiWTrLesChxL5bAR8Q58YiIVJISdBERqZtCG0Krk52luLwc2L+l9L7u2QfLrq8g17lu/xbYUspx/6DCBL5Y0l4igW+qBF5EysVnCboxpiXwBHAm0BjYDXwJPG6t3V/OOhKBNmUc3mutjat8pCIiUq8FBDnDNMZ2LrnfWmds9qLEff9WOLCtcNkKmSnHrjc/B1I3O0tp/IOhQatiyXvxBL4NRDRR/3cRAXyUoBtj2gO/Ak2Ar4C1QH/gLuBMY8wQa+1x/rJ5pAEvlbL/kA9CFRERKZ0xTj/zyDhoe8rRx7MPOf3WiyftRdv7t5acObU0+dnOg64pG0s/HhDiPLxaIoFv7Yz/3qC1M5ykEniResFXLeiv4yTnd1prXy3aaYx5AbgHeAq4pZx1HbDWjvdRXCIiIr4RHAFNujpLabLT4UBpCXzh+vBxvkzOy3JGpUnZUPrxgJCSiXtUc6dfvDFg/ABTmMAXX/t5k/oyjx1xXal1UcHzC9cBwc6DtyFREBztrP0Dy/uOi9RblU7QjTHtgNOBROC1Iw4/BtwEXGWMuddam1HZ+4mIiNRIwZHQ9CRnKU3WwSNa4LfB/kTvdlmzqxbJy/J2v6nNAkILE/aokuuQ6MLt6KOPKcmXesYXLeijCtdTrLUFxQ9Ya9ONMXNxEviBwNRy1BdsjLkSaA1kAMuBWdaW9cj90YwxpTx+D0CX8tYhIiLiUyFRENINmnYr/XhW2rFb4LPKmGW1tsk7DIcOO/39T1RZSf6RCX6pyb6SfKn5fJGgFz1lU9ZH+g04CXonypegxwEfHrFvizHmWmvtzBMLUUREpIYLiYa4aIjrXvrxwwdKtsCn7wZb4Dzcai1QxtoWlHGsgP9v786DJSvLO45/n9mYDWZkCzBurDIFKswYFEwERAlC2CJUqCQqJGCMGDSaUsstoqaiiSYKptREBQNGiBjRGBJxAUGNWgHEKIMCw7gwA4gjszA7PPnjPc30NLdn7p3b3ef0vd9P1akz/Z7TfZ9+q3vOr0+/522SMe7f3sZ2tlVtWzaWbw42rIKNq8owoG3P5e2cXob8GXNg+pwy1/702dXt2dXtjvbHt420T7WeNtNrBTRuvQjo86p1t4/2rfb5o3isy4CbgR8Ba4ADgNdQhsn8V0QcnZm37+hBMnPxSO3VmfVFo6hDkqRmmTW/LPs8s+5Kdl4mbFpbQvvG1W3rVR23R1qv2nq7lyG/12JKR4jfTuBvtc+Y2z3wz94T5u7V+zrVaIOYB731MTJ3tGNmXtzR9EPgVRGxFngD8E7gzJ5WJ0mSBiOijNXfZVdgwc49RiZsemRrcH883NcQ8kes77HyIWRTDyef23U/WLCoLPstgv2OLB/WNGH1IqC3zpDP67J9t479dsZHKQF9hHmvJEnSpBFRZtTZZW6ZyWZntIf8Tetg8yNt60c62taVts3rRmhf+8R9Ht3U2+cLsGY53Lkc7vzS1rY9DoIFi0tgX7C4fLMyfWbv/7Zq0YuA/uNqfUiX7QdX6/Fcdv5gtZ4zjseQJEnaNuT32qNbuoT7EcL8SB8EHt9WrVf9oqw7tebU/8HV5faUaeUC5P2qM+0LFsNeh8KUqb1/juq7XgT0G6r1iRExpX0ml4jYFXg+sB74zjj+xtHVusvPs0mSJDXA1GkwdV656LcXHt0Cv7wTlt8K990C990KD/wIOie3e2wLrLi9LLdcVtqmz4Z9j9h2eMyTnu5FrENg3AE9M++JiOspM7VcCFzatvliylnvj7XmQI+I6cCBwObMvKe1Y0QcBqzIzG1+ii0ingZ8uLp55XjrlSRJGhpTp5WZffY5HBa9vLRtXg/3/18J6/fdUsL7SL9Qu3kd/OzbZWmZtfvWsL5gcfn33L0H81w0ar26SPTVwLeBSyLiBGAJ8FzgeMrQlre27bug2v5T4Olt7WcDb46IG4B7KbO4HAicAswErgPe36N6JUmShtP0WfCUo8rSsv5hWH5bdaa9WtYsf+J916+Eu79alpZ5TykXnrYC+75HlCkoh03r2oIND5f+aF/PnAcLT621vLHoSUCvzqI/B3gXcBJwMrACuAS4uPOseBc3UOZUP5IypGUO8DDwTcq86Fdk5g5ngpEkSZp0Zs2HA48vS8vqFW2BvTrTPtIPXq36eVmWfLFqCNjzkK1j2fdbVM7gT9ul/8+jNRVnZ8Ae7fqxLSM/7pOPmnwBHSAzfw6cN4r9lrF16sX29m8A/hCRJElSL+y2L+x2Chx6SrmdCSuXbhvYV9wOWzZ03DHhoR+X5fbPlKYp00tIf3zmmEUlxI90EWpm+VGqnQnYG1Z1D9njseHh3j9mHw1iHnRJkiTVLQL2OLAszzq7tD26GR5c0nYR6m3w4B0jXIS6uRpCc9vWthlzYd9nlzPr2wTtVU+8/6BMm1W+TZg5f9v1/KfWU89OMqBLkiRNVlOnw77PKsvic0vbpnVw/w+2PdO+coSJ9DathZ9+q/c1TZ/9xIA92vUghuEMgAFdkiRJW82YDU99Xlla1q3suAj1Flj7QPfHmD5n5wL2zPkwbUY/ntVQMaBLkiRp+2bvDgedUBYo48xXL4cHfggxZduAPXOeIXucDOiSJEkamwiYt6As6rkpdRcgSZIkaSsDuiRJktQgBnRJkiSpQQzokiRJUoMY0CVJkqQGMaBLkiRJDWJAlyRJkhrEgC5JkiQ1iAFdkiRJahADuiRJktQgBnRJkiSpQQzokiRJUoMY0CVJkqQGMaBLkiRJDWJAlyRJkhrEgC5JkiQ1SGRm3TUMTET8atasWbsvXLiw7lIkSZI0gS1ZsoT169evzMw9xnrfyRbQ7wV2A5bV8OcPrdZ31vC3Jwr7cPzsw/GzD8fPPhw/+7A37Mfxsw+7ezqwOjP3H+sdJ1VAr1NE3AKQmYvrrmVY2YfjZx+On304fvbh+NmHvWE/jp992B+OQZckSZIaxIAuSZIkNYgBXZIkSWoQA7okSZLUIAZ0SZIkqUGcxUWSJElqEM+gS5IkSQ1iQJckSZIaxIAuSZIkNYgBXZIkSWoQA7okSZLUIAZ0SZIkqUEM6JIkSVKDGNAlSZKkBjGg91lEPDkiPhkRyyNiY0Qsi4gPRsST6q6t6SJij4g4PyI+HxF3R8T6iFgVEd+MiD+JCF+/OyEiXhYRWS3n113PMImI346Iz0XEiur9vCIiro+Ik+uubRhExClVf/2iej8vjYjPRsTRddfWJBFxVkRcGhE3R8Tq6r165Q7uc0xEXBcRKyNiXUT8ICJeFxFTB1V3k4ylDyPi4Ih4U0R8PSJ+HhGbIuKBiPhCRBw/6NqbYmdehx33/0TbseagftY6EU2ru4CJLCIOBL4N7A18AbgTOAp4LXBSRDw/M39VY4lNdzbwEWAFcAPwM+A3gN8DPg68JCLOTn8Od9Qi4inApcBaYG7N5QyViHgb8G7gIeBLlNflnsCRwHHAdbUVNwQi4n3AG4FfAddS+vEg4HTgpRHx8swc9cF/gnsb8GzK+/QXwKHb2zkiTgc+B2wArgZWAqcC/wA8n/J/6WQzlj58N/D7wB2U9/FK4BnAacBpEfHazLykv+U20pheh+0i4lTgj/FYs/My06VPC/BlIIE/72j/+6r9o3XX2OQFeCHlIDOlo30fSlhP4KV11zksCxDAV4F7gL+r+u/8uusahoUScBL4CrDrCNun111jk5fqPfsocD+wd8e246u+XVp3nU1Zqj45uHrPHlf1z5Vd9t0NeBDYCDynrX0m5QRRAufU/Zwa3ofnAkeO0H4ssKnq233rfk5N7sOO++1VvdevAm6s7ndQ3c9n2BaHCPRJRBwAnAgsA/6xY/NfAY8AL4uIOQMubWhk5tcz8z8y87GO9vuBj1Y3jxt4YcPrIsqHnvMorz+NQjWU6n3AOuAPMnNN5z6ZuXnghQ2Xp1GGVH43Mx9s35CZNwBrKAd1UfokM+/KKu3swFmUvrsqM/+37TE2UM6AAvxZH8pstLH0YWZenpm3jdD+DUrAnAEc0/sqm22Mr8N2/1StL+x1TZOJAb1/Xlitrx8hYK4BvgXMBp436MImiFYg2lJrFUMiIhYC7wU+lJk31V3PkDkG2J/y1fevq3HUb4qI1zp2etTuopyJPCoi9mzfEBEvAHalfLujsWsda/57hG03UT5YHhMRuwyupAnFY80YRMS5wBnAq9IhvOPiGPT+eUa1/kmX7XdRzrAfAnxtIBVNEBExDXh5dXOkg5LaVP11BWVY0FtqLmcY/Wa1fgC4FXhm+8aIuAk4KzN/OejChkVmroyIN1GG990REddSxqIfSBnn+xXgT+urcKh1PdZk5paIuBc4DDgAWDLIwoZdRDwNOIHyIccTGztQ9deHKMNgrq25nKFnQO+fedV6VZftrfb5/S9lwnkvcDhwXWZ+ue5ihsA7KBcy/lZmrq+7mCG0d7V+FXAv8CLgu5RhGx8Afgf4LA632q7M/GBELAM+CVzQtulu4PLOoS8aNY81fVB94/BpYBfgjZn565pLarRqKOCnKBeFXlRzOROCQ1zqE9XaGUjGICIuAt5AmRHnZTWX03gRcRTlrPkHMvN/6q5nSLWmqQvKmfKvZebazPwRcCZldoNjHe6yfRHxRuAa4HLKmfM5wGJgKfDpiPjb+qqb0DzWjFE1NeUVlBlwrgbeX29FQ+EvKBfVXuCHmd4woPdP66zFvC7bd+vYTzsQERdSvj67Azg+M1fWXFKjtQ1t+Qnw9prLGWatg83SzLy9fUP1jUTrW5yjBlrVEImI4ygX2n4xM1+fmUszc11m3kr5kHMf8Ibq4nqNjceaHqrC+ZWUmZv+DfijnbhIclKJiIOBvwYuy0ynm+0RA3r//LhaH9Jl+8HVutsYdbWJiNcBHwZ+SAnn99db0VCYS3n9LQQ2tP1gRFJmEgL456rtg3UVOQRa7+WHu2xvBfhZ/S9laP1utb6hc0NmrgO+RzkeHTnIoiaIrsea6kP6/pQLHJcOsqhhVPXXZ4BzgH+lzNrkxaE7dhhlKNB57ceZ6lhzbLXPXVXbGbVVOWQcg94/rQPRiRExpX0ml4jYlfLV2XrgO3UUN0yqi8veC3wfeHFmPlRvRUNjI/CJLtsWUcLQNykHeIe/dHcTJeAcHBEzMnNTx/bDq/WygVY1XFoziHSbSrHV3tm32rGvA38InEQJl+1eQJkt7KbM3DjowoZJRMygnDE/HfgX4LzOGdjU1TK6H2tOofwOwmeB1fj/5KgZ0PskM++JiOspM7VcSPn1xpaLKeMvP5aZzke9HRHxduBdwC3AiQ5rGb1q+MX5I22LiHdSAvqnMvPjg6xr2GTmQxFxNSUEvYOtc0sTES+mXCS6CmcU2p6bgdcAr4yIj2Xmfa0NEfESygmLDZQf1tHYXEMZPnRORFzamgs9ImYC76n2+UhdxQ2D6oLQfwdOpgTNVxrORy8zv0/3Y82NlID+lsy8e4BlDT0Den+9mnLAuSQiTqBMcfVcyq9z/QR4a421NV5EvIISzh+lHOAviojO3ZZl5uUDLk2Tz+sp7923VvN2f48yi8uZlNfnBZn5cH3lNd41lHnOXwQsiYjPU35pcCFl+EsAb3be5KIaBnBGdXOfan10RFxe/fuhzPxLgMxcHREXUPr4xoi4ivJT9adRpmC8hnKh46Qylj6k/PDdycBDlOsh3jHCsebGzLyxT+U20hj7UD1mQO+j6iz6cygh8yTKfwArgEuAiz0bvEP7V+upwOu67PMNyqwQUt9k5oMR8VzK2fMzKT8wtgb4T+BvMtOhatuRmY9FxMmUbxPPofThbEqQvA64JDOvr7HEpjkCeEVH2wHVAvBT4PFglJnXRsSxlJM+LwVmUqavfD2lbyfjRY5HMPo+bB1r9qR8S9bNjT2qbVgcwRheh+qtmJzvW0mSJKmZnMVFkiRJahADuiRJktQgBnRJkiSpQQzokiRJUoMY0CVJkqQGMaBLkiRJDWJAlyRJkhrEgC5JkiQ1iAFdkiRJahADuiRJktQgBnRJkiSpQQzokiRJUoMY0CVJkqQGMaBLkiRJDWJAlyRJkhrEgC5JkiQ1yP8DZo4DPIWMQEIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 372
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(_512_running_train_losses, label = '512 weights Training Losses')\n",
    "plt.plot(_512_test_losses, label = '512 weights Test Losses')\n",
    "\n",
    "plt.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for vgg16\n",
    "# input_size, output_size = 25088, 102\n",
    "# checkpoint_path = \"rabakClassifier1.pth\"\n",
    "# classifier = RabakNetwork(input_size, output_size, [16558, 10928 ,7212, 4760, 3141, 2073, 1368, 903, 596, 393, 259])\n",
    "# model.classifier = classifier\n",
    "\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.classifier.parameters(), lr = 0.005)\n",
    "# running_train_losses, test_losses = myF.train(model, trainloader, testloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myF.validate_model(model, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, accuracy = myF.validate(model, dataloaders['test'], criterion)\n",
    "\n",
    "print(f'Test Loss: {(test_loss / len(validationloader)):.3f}',\n",
    "      f'Test Accuracy: {((accuracy / len(dataloaders[\"test\"])) * 100):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if changes were made to an external module, this snippet allowes to reload in without restarting the kernal\n",
    "#very useful!\n",
    "import importlib\n",
    "\n",
    "importlib.reload(myF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.class_to_idx = image_datasets['train'].class_to_idx\n",
    "model.hyper_params = hyper_params\n",
    "model.input_sizes = model_input_sizes\n",
    "myF.save_model(model, model_name, optimizer,optimizer_name, criterion, dataloaders, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): RabakNetwork(\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    )\n",
      "    (output): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ") AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.01\n",
      ") NLLLoss() OrderedDict([('train', <torch.utils.data.dataloader.DataLoader object at 0x000001AA05A3DD90>), ('test', <torch.utils.data.dataloader.DataLoader object at 0x000001AA05A50880>), ('validate', <torch.utils.data.dataloader.DataLoader object at 0x000001AA05A504F0>)])\n"
     ]
    }
   ],
   "source": [
    "model,optimizer, criterion, dataloaders,  hyper_params = myF.load_rabak_network_checkpoint(checkpoint_path)\n",
    "print(model, optimizer, criterion, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    image = process_image(image_path)\n",
    "    image = image.to('cpu')\n",
    "    model = model.to('cpu')\n",
    "    with torch.no_grad():\n",
    "        output = model.forward(image)\n",
    "        \n",
    "    ps = torch.exp(output)\n",
    "    top_ps, top_class = ps.topk(5)\n",
    "    return top_ps.numpy(), top_class.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, add_batch=True):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    with Image.open(image) as im:\n",
    "        print(im)\n",
    "        im = im.resize((256,256))\n",
    "        width, height = im.width, im.height\n",
    "        \n",
    "        new_width, new_height = 224, 224\n",
    "        left = (width - new_width)/2\n",
    "        top = (height - new_height)/2\n",
    "        right = (width + new_width)/2\n",
    "        bottom = (height + new_height)/2\n",
    "        im = im.crop((round(left), round(top), round(right), round(bottom)))\n",
    "        \n",
    "        np_image = np.array(im)\n",
    "        \n",
    "        #divide by the max value to get an array of values between 0 and 1\n",
    "        np_normalized = np_image / 255\n",
    "        \n",
    "        #subtract the means from each color channel, then divide by the standard deviation\n",
    "        np_normalized = (np_normalized - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "        \n",
    "        #reorder the dimensions so that the color channel is first, as pytorch expects\n",
    "        np_normalized = np_normalized.transpose(2,0,1)\n",
    "        \n",
    "        #add a fourth dimension to indicate batch size for torchvision\n",
    "        if add_batch:\n",
    "            np_normalized = np_normalized[np.newaxis,:]\n",
    "    \n",
    "        # Turn into a torch tensor\n",
    "        image = torch.from_numpy(np_normalized)\n",
    "        image = image.float()\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir_path = \"assets/flowers/test\"\n",
    "test_image, label_dir =  myF.get_random_image_and_label(test_dir_path)\n",
    "test_image = test_dir_path + \"/\" + label_dir + \"/\" + test_image\n",
    "\n",
    "predictions, classes = predict(test_image, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_arr = predictions[0]\n",
    "classes_arr = classes[0]\n",
    "\n",
    "idx_to_class = {val: key for key, val in model.class_to_idx.items()}\n",
    "top_classes = [idx_to_class[val] for val in classes_arr]\n",
    "\n",
    "labels = [cat_to_name[val] for val in top_classes]\n",
    "\n",
    "fig, ((ax1,ax2)) = plt.subplots(figsize=(6,7), nrows=2)\n",
    "with Image.open(test_image) as img:\n",
    "    ax1.imshow(img)\n",
    "ax1.axis('off')\n",
    "ax1.set_title(cat_to_name[label_dir])\n",
    "    \n",
    "y_pos = np.arange(len(labels))\n",
    "ax2.barh(y_pos, predictions_arr)\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(labels)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'runtime: {time.perf_counter() - start_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1dc99d39e6a07fb60e42a7652aaee3ef04ed7f456a6084f44bbf76fc83210070"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
